{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10013524,"sourceType":"datasetVersion","datasetId":6164966}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":" !git clone https://github.com/NadaAbodeshish/augmented-e2eET-Skeleton-Based-HGR-Using-Data-Level-Fusion.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-26T11:59:23.593168Z","iopub.execute_input":"2024-11-26T11:59:23.593797Z","iopub.status.idle":"2024-11-26T11:59:27.030959Z","shell.execute_reply.started":"2024-11-26T11:59:23.593767Z","shell.execute_reply":"2024-11-26T11:59:27.030137Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'augmented-e2eET-Skeleton-Based-HGR-Using-Data-Level-Fusion'...\nremote: Enumerating objects: 476, done.\u001b[K\nremote: Counting objects: 100% (174/174), done.\u001b[K\nremote: Compressing objects: 100% (111/111), done.\u001b[K\nremote: Total 476 (delta 127), reused 110 (delta 63), pack-reused 302 (from 1)\u001b[K\nReceiving objects: 100% (476/476), 58.82 MiB | 44.95 MiB/s, done.\nResolving deltas: 100% (306/306), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd augmented-e2eET-Skeleton-Based-HGR-Using-Data-Level-Fusion\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T11:59:27.032679Z","iopub.execute_input":"2024-11-26T11:59:27.033024Z","iopub.status.idle":"2024-11-26T11:59:27.040141Z","shell.execute_reply.started":"2024-11-26T11:59:27.032994Z","shell.execute_reply":"2024-11-26T11:59:27.039188Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/augmented-e2eET-Skeleton-Based-HGR-Using-Data-Level-Fusion\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!ls /kaggle/input/dhg2814","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T11:59:27.041178Z","iopub.execute_input":"2024-11-26T11:59:27.041405Z","iopub.status.idle":"2024-11-26T11:59:28.150265Z","shell.execute_reply.started":"2024-11-26T11:59:27.041371Z","shell.execute_reply":"2024-11-26T11:59:28.149326Z"}},"outputs":[{"name":"stdout","text":"'DHG1428.mVOs-3d.28g-noisy(raw).960px-[allVOs].adaptive-mean'\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!cp -r /kaggle/input/dhg2814/* /kaggle/working/augmented-e2eET-Skeleton-Based-HGR-Using-Data-Level-Fusion/images_d/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T11:59:28.152977Z","iopub.execute_input":"2024-11-26T11:59:28.153411Z","iopub.status.idle":"2024-11-26T12:01:12.053186Z","shell.execute_reply.started":"2024-11-26T11:59:28.153381Z","shell.execute_reply":"2024-11-26T12:01:12.052208Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"%cd experiments.server","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T12:01:12.054589Z","iopub.execute_input":"2024-11-26T12:01:12.054969Z","iopub.status.idle":"2024-11-26T12:01:12.061662Z","shell.execute_reply.started":"2024-11-26T12:01:12.054930Z","shell.execute_reply":"2024-11-26T12:01:12.060879Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/augmented-e2eET-Skeleton-Based-HGR-Using-Data-Level-Fusion/experiments.server\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install pytorchcv\n!pip install matplotlib\n!pip install geffnet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T12:01:12.062880Z","iopub.execute_input":"2024-11-26T12:01:12.063194Z","iopub.status.idle":"2024-11-26T12:01:37.703746Z","shell.execute_reply.started":"2024-11-26T12:01:12.063159Z","shell.execute_reply":"2024-11-26T12:01:37.702881Z"}},"outputs":[{"name":"stdout","text":"Collecting pytorchcv\n  Downloading pytorchcv-0.0.73-py2.py3-none-any.whl.metadata (134 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.2/134.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorchcv) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pytorchcv) (2.32.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from pytorchcv) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from pytorchcv) (0.19.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pytorchcv) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pytorchcv) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pytorchcv) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pytorchcv) (2024.8.30)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->pytorchcv) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->pytorchcv) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->pytorchcv) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->pytorchcv) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->pytorchcv) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->pytorchcv) (2024.6.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->pytorchcv) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->pytorchcv) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->pytorchcv) (1.3.0)\nDownloading pytorchcv-0.0.73-py2.py3-none-any.whl (585 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.2/585.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pytorchcv\nSuccessfully installed pytorchcv-0.0.73\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nCollecting geffnet\n  Downloading geffnet-1.0.2-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.10/site-packages (from geffnet) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from geffnet) (0.19.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->geffnet) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->geffnet) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->geffnet) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->geffnet) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->geffnet) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->geffnet) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->geffnet) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->geffnet) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4->geffnet) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4->geffnet) (1.3.0)\nDownloading geffnet-1.0.2-py3-none-any.whl (40 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: geffnet\nSuccessfully installed geffnet-1.0.2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!python mVO.e2eEnsembleTuning.py -IG 0 -nC 28 -mVOs top-down custom front-away -dsN DHG1428 -IISE 0 -ISIS 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T12:01:37.705105Z","iopub.execute_input":"2024-11-26T12:01:37.705397Z","iopub.status.idle":"2024-11-26T14:54:42.345523Z","shell.execute_reply.started":"2024-11-26T12:01:37.705369Z","shell.execute_reply":"2024-11-26T14:54:42.344664Z"}},"outputs":[{"name":"stdout","text":"\nDataloader has been created successfully...\nThe dataloader has 28 (28) classes: ['01-Grab', '02-Tap', '03-Expand', '04-Pinch', '05-RotationCW', '06-RotationCCW', '07-SwipeRight', '08-SwipeLeft', '09-SwipeUp', '10-SwipeDown', '11-SwipeX', '12-Swipe+', '13-SwipeV', '14-Shake', '15-Grab', '16-Tap', '17-Expand', '18-Pinch', '19-RotationCW', '20-RotationCCW', '21-SwipeRight', '22-SwipeLeft', '23-SwipeUp', '24-SwipeDown', '25-SwipeX', '26-Swipe+', '27-SwipeV', '28-Shake']\nTraining set [len=1960, img_sz=(960, 960)] loaded on device: cuda:0\nValidation set [len=840, img_sz=(960, 960)] loaded on device: cuda:0\nPreviewing loaded data [1] and applied transforms [2]...\n\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|███████████████████████████████████████| 83.3M/83.3M [00:00<00:00, 196MB/s]\n\nmetrics= [<bound method accuracyMultiVOs_0 of e2eTunerLossWrapper()>, <bound method accuracyMultiVOs_1 of e2eTunerLossWrapper()>, <bound method accuracyMultiVOs_2 of e2eTunerLossWrapper()>, <bound method e2eTunerLossWrapper.accuracyTuner of e2eTunerLossWrapper()>]\nBatch Size: 16, Image Size: 224, Epochs: [20, 20]\n\nModel FROZEN [a].\n/opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(file, map_location=device, **torch_load_kwargs)\n>> @i224a --- pct_start: 0.55 --- learning_rate: 0.0010000000474974513\nepoch     train_loss  valid_loss  accuracyTopDown  accuracyCustom  accuracyFrontAway  accuracyTuner  time    \n0         11.412301   9.545535    0.236905         0.297619        0.295238           0.385714       03:11     \n1         9.800676    8.981922    0.280952         0.265476        0.308333           0.508333       03:12     \n2         8.486978    7.226252    0.350000         0.336905        0.425000           0.684524       03:11     \n3         7.746442    6.926530    0.322619         0.379762        0.470238           0.691667       03:11     \n4         7.395293    6.806293    0.380952         0.402381        0.465476           0.722619       03:11     \n5         6.777337    5.905871    0.416667         0.480952        0.516667           0.769048       03:11     \n6         6.718433    5.761797    0.407143         0.498810        0.521429           0.780952       03:12     \n7         6.411450    5.777288    0.403571         0.491667        0.536905           0.788095       03:12     \n8         6.443306    5.556404    0.438095         0.492857        0.552381           0.805952       03:13     \n9         5.971407    5.664479    0.427381         0.490476        0.551190           0.783333       03:13     \n10        6.013577    5.271349    0.485714         0.532143        0.552381           0.821429       03:12     \n11        5.793613    5.244104    0.469048         0.525000        0.576190           0.821429       03:13     \n12        5.570345    5.346951    0.485714         0.509524        0.569048           0.808333       03:12     \n13        5.297267    4.881438    0.482143         0.557143        0.582143           0.852381       03:12     \n14        5.035422    4.918499    0.500000         0.558333        0.590476           0.828571       03:13     \n15        4.917800    4.998393    0.515476         0.564286        0.561905           0.823810       03:14     \n16        4.732888    4.813353    0.527381         0.566667        0.597619           0.832143       03:14     \n17        4.845856    4.621398    0.502381         0.594048        0.608333           0.860714       03:12     \n18        4.519242    4.722888    0.508333         0.577381        0.604762           0.835714       03:11     \n19        4.450396    4.873464    0.514286         0.555952        0.589286           0.830952       03:13     \n@outsidersCustomCallback: Training completed and best i224a model loaded!\n-- [ i224a] - 0.5024 - 0.5940 - 0.6083 - 0.8607 - 01:06\n\nModel UNFROZEN [b].\n>> @i224b --- pct_start: 0.55 --- learning_rate: 4.786300905834651e-06\nepoch     train_loss  valid_loss  accuracyTopDown  accuracyCustom  accuracyFrontAway  accuracyTuner  time    \n0         4.374888    4.689847    0.520238         0.576190        0.611905           0.855952       03:28     \n1         4.403830    4.836117    0.507143         0.557143        0.602381           0.836905       03:27     \n2         4.281494    4.590096    0.504762         0.592857        0.621429           0.853571       03:26     \n3         4.262815    4.416319    0.529762         0.617857        0.636905           0.869048       03:26     \n4         4.274384    4.423351    0.533333         0.594048        0.640476           0.858333       03:26     \n5         4.011572    4.457783    0.515476         0.595238        0.640476           0.861905       03:27     \n6         4.116167    4.303003    0.534524         0.608333        0.644048           0.873810       03:27     \n7         4.064116    4.220098    0.557143         0.630952        0.642857           0.877381       03:28     \n8         3.861190    4.527694    0.521429         0.577381        0.628571           0.854762       03:26     \n9         3.980180    4.311978    0.542857         0.610714        0.638095           0.859524       03:31     \n10        3.851902    4.231971    0.551190         0.607143        0.648810           0.877381       03:29     \n11        3.980326    4.406190    0.529762         0.611905        0.633333           0.859524       03:33     \n12        3.672642    4.381470    0.541667         0.605952        0.634524           0.861905       03:28     \n13        3.714396    4.199956    0.541667         0.598810        0.670238           0.878571       03:26     \n14        3.617251    4.271258    0.557143         0.625000        0.638095           0.869048       03:26     \n15        3.545193    4.306562    0.544048         0.596429        0.645238           0.863095       03:25     \n16        3.538277    4.133078    0.553571         0.634524        0.658333           0.872619       03:25     \n17        3.639175    4.136387    0.559524         0.634524        0.657143           0.878571       03:24     \n18        3.500241    4.144520    0.553571         0.630952        0.658333           0.873810       03:25     \n19        3.535001    4.231460    0.560714         0.608333        0.644048           0.869048       03:25     \n@outsidersCustomCallback: Training completed and best i224b model loaded!\n-- [ i224b] - 0.5595 - 0.6345 - 0.6571 - 0.8786 - 02:17\n>> @i224bf --- pct_start: 0.55 --- learning_rate: 4.78630090583465e-07\nepoch     train_loss  valid_loss  accuracyTopDown  accuracyCustom  accuracyFrontAway  accuracyTuner  time    \n0         3.636588    4.236868    0.527381         0.600000        0.654762           0.870238       03:26     \n1         3.581978    4.166362    0.550000         0.635714        0.645238           0.873810       03:27     \n2         3.614792    4.189526    0.541667         0.615476        0.658333           0.871429       03:27     \n3         3.560180    4.175470    0.541667         0.635714        0.654762           0.872619       03:27     \n4         3.606810    4.119228    0.560714         0.628571        0.655952           0.883333       03:27     \n5         3.647626    4.378873    0.547619         0.605952        0.619048           0.860714       03:26     \n6         3.653434    4.188245    0.558333         0.613095        0.664286           0.873810       03:27     \n7         3.627422    4.283241    0.552381         0.607143        0.635714           0.869048       03:26     \n8         3.548408    4.253482    0.553571         0.610714        0.639286           0.865476       03:26     \n9         3.507023    4.024611    0.560714         0.638095        0.671429           0.888095       03:27     \n@outsidersCustomCallback: Training completed and best i224bf model loaded!\n-- [i224bf] - 0.5607 - 0.6381 - 0.6714 - 0.8881 - 02:51\nTime Elapsed ~ 02h:51m:53s\naccuracies@e2eT: {'Top-Down': 0.5607, 'Custom': 0.6381, 'Front-Away': 0.6714, 'Tuner': 0.8881}\ne2eT_MaxA: 0.8881 @02h:52m:45s\nTraining completed @mVO.e2eEnsembleTuning ->> [068d]-261124.1201 ->- e2eT-DHG1428.3d-28G-[td_cm_fa]-i20\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}