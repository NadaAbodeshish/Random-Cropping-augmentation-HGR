{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hn6uaZYCINDy"
      },
      "outputs": [],
      "source": [
        "! pip install -q keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XBLSQB8bRtdT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import scipy.ndimage.interpolation as inter\n",
        "from scipy.signal import medfilt\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "from keras.optimizers import *\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "# from keras.layers.core import *\n",
        "# from tensorflow.keras.callbacks import *\n",
        "# from keras.layers.convolutional import *\n",
        "from keras import backend as K\n",
        "import keras\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Dd8w2Uaks3"
      },
      "source": [
        "1. Define configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EyxDYnOJaotB"
      },
      "outputs": [],
      "source": [
        "random.seed(1234)\n",
        "\n",
        "class Config():\n",
        "    def __init__(self):\n",
        "        self.frame_l = 32 # the length of frames\n",
        "        self.joint_n = 12 # the number of joints\n",
        "        self.joint_n = 22 # the number of joints\n",
        "        self.joint_d = 3 # the dimension of joints\n",
        "        self.clc_coarse = 14 # the number of coarse class\n",
        "        self.clc_fine = 28 # the number of fine-grained class\n",
        "        self.feat_d = 231\n",
        "        self.filters = 64\n",
        "C = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KG-n2OiaF4h"
      },
      "source": [
        "2. Define data processing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gToZ5f6haNKs"
      },
      "outputs": [],
      "source": [
        "# Temple resizing function\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import scipy.ndimage.interpolation as inter\n",
        "from scipy.signal import medfilt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "###################################################################################\n",
        "\n",
        "\n",
        "#Rescale to be 64 frames\n",
        "def zoom(p,target_l=64,joints_num=25,joints_dim=3):\n",
        "    l = p.shape[0]\n",
        "    p_new = np.empty([target_l,joints_num,joints_dim])\n",
        "    for m in range(joints_num):\n",
        "        for n in range(joints_dim):\n",
        "            p[:,m,n] = medfilt(p[:,m,n],3)\n",
        "            p_new[:,m,n] = inter.zoom(p[:,m,n],target_l/l)[:target_l]\n",
        "    return p_new\n",
        "\n",
        "def sampling_frame(p,C):\n",
        "    full_l = p.shape[0] # full length\n",
        "    if random.uniform(0,1)<0.5: # aligment sampling\n",
        "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
        "        s = random.randint(0, full_l-int(valid_l))\n",
        "        e = s+valid_l # sample end point\n",
        "        p = p[int(s):int(e),:,:]\n",
        "    else: # without aligment sampling\n",
        "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
        "        index = np.sort(np.random.choice(range(0,full_l),int(valid_l),replace=False))\n",
        "        p = p[index,:,:]\n",
        "    p = zoom(p,C.frame_l,C.joint_n,C.joint_d)\n",
        "    return p\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "def get_CG(p,C):\n",
        "    M = []\n",
        "    iu = np.triu_indices(C.joint_n,1,C.joint_n)\n",
        "    for f in range(C.frame_l):\n",
        "        #distance max\n",
        "        d_m = cdist(p[f],np.concatenate([p[f],np.zeros([1,C.joint_d])]),'euclidean')\n",
        "        d_m = d_m[iu]\n",
        "        M.append(d_m)\n",
        "    M = np.stack(M)\n",
        "    return M\n",
        "\n",
        "def normlize_range(p):\n",
        "    # normolize to start point, use the center for hand case\n",
        "    p[:,:,0] = p[:,:,0]-np.mean(p[:,:,0])\n",
        "    p[:,:,1] = p[:,:,1]-np.mean(p[:,:,1])\n",
        "    p[:,:,2] = p[:,:,2]-np.mean(p[:,:,2])\n",
        "    return p\n",
        "\n",
        "def cm_analysis(y_true, y_pred, filename, labels, ymap=None, figsize=(8,8)):\n",
        "    \"\"\"\n",
        "    Generate matrix plot of confusion matrix with pretty annotations.\n",
        "    The plot image is saved to disk.\n",
        "    args:\n",
        "      y_true:    true label of the data, with shape (nsamples,)\n",
        "      y_pred:    prediction of the data, with shape (nsamples,)\n",
        "      filename:  filename of figure file to save\n",
        "      labels:    string array, name the order of class labels in the confusion matrix.\n",
        "                 use `clf.classes_` if using scikit-learn models.\n",
        "                 with shape (nclass,).\n",
        "      ymap:      dict: any -> string, length == nclass.\n",
        "                 if not None, map the labels & ys to more understandable strings.\n",
        "                 Caution: original y_true, y_pred and labels must align.\n",
        "      figsize:   the size of the figure plotted.\n",
        "    \"\"\"\n",
        "    if ymap is not None:\n",
        "        y_pred = [ymap[yi] for yi in y_pred]\n",
        "        y_true = [ymap[yi] for yi in y_true]\n",
        "        labels = [ymap[yi] for yi in labels]\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "    cm_perc = cm / cm_sum.astype(float) * 100\n",
        "    annot = np.empty_like(cm).astype(str)\n",
        "    nrows, ncols = cm.shape\n",
        "    for i in range(nrows):\n",
        "        for j in range(ncols):\n",
        "            c = cm[i, j]\n",
        "            p = cm_perc[i, j]\n",
        "            if i == j:\n",
        "                s = cm_sum[i]\n",
        "                #annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
        "                annot[i, j] = '%.1f' % (p)\n",
        "            elif c == 0:\n",
        "                annot[i, j] = ''\n",
        "            else:\n",
        "                #annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
        "                annot[i, j] = '%.1f' % (p)\n",
        "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "    cm.index.name = 'Actual'\n",
        "    cm.columns.name = 'Predicted'\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(cm, annot=annot, fmt='', ax=ax, cbar=False, cmap=\"YlGnBu\")\n",
        "    plt.savefig(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDzVwCSYv6bS"
      },
      "source": [
        "3. Define network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yVHcN8sGav6m"
      },
      "outputs": [],
      "source": [
        "\n",
        "def poses_diff(x):\n",
        "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
        "    x = tf.subtract(x[:,1:,...],x[:,:-1,...])\n",
        "    x = tf.image.resize(x,size=[H,W])\n",
        "    return x\n",
        "\n",
        "def pose_motion(P,frame_l):\n",
        "    P_diff_slow = Lambda(lambda x: poses_diff(x))(P)\n",
        "    P_diff_slow = Reshape((frame_l,-1))(P_diff_slow)\n",
        "    P_fast = Lambda(lambda x: x[:,::2,...])(P)\n",
        "    P_diff_fast = Lambda(lambda x: poses_diff(x))(P_fast)\n",
        "    P_diff_fast = Reshape((int(frame_l/2),-1))(P_diff_fast)\n",
        "    return P_diff_slow,P_diff_fast\n",
        "\n",
        "def c1D(x,filters,kernel):\n",
        "    x = Conv1D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    return x\n",
        "\n",
        "def block(x,filters):\n",
        "    x = c1D(x,filters,3)\n",
        "    x = c1D(x,filters,3)\n",
        "    return x\n",
        "\n",
        "def d1D(x,filters):\n",
        "    x = Dense(filters,use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    return x\n",
        "\n",
        "def build_FM(frame_l=32,joint_n=22,joint_d=2,feat_d=231,filters=16):\n",
        "    M = Input(shape=(frame_l,feat_d))\n",
        "    P = Input(shape=(frame_l,joint_n,joint_d))\n",
        "\n",
        "    diff_slow,diff_fast = pose_motion(P,frame_l)\n",
        "\n",
        "    x = c1D(M,filters*2,1)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = c1D(x,filters,3)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = c1D(x,filters,1)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "\n",
        "    x_d_slow = c1D(diff_slow,filters*2,1)\n",
        "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
        "    x_d_slow = c1D(x_d_slow,filters,3)\n",
        "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
        "    x_d_slow = c1D(x_d_slow,filters,1)\n",
        "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
        "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
        "\n",
        "    x_d_fast = c1D(diff_fast,filters*2,1)\n",
        "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
        "    x_d_fast = c1D(x_d_fast,filters,3)\n",
        "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
        "    x_d_fast = c1D(x_d_fast,filters,1)\n",
        "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
        "\n",
        "    x = concatenate([x,x_d_slow,x_d_fast])\n",
        "    x = block(x,filters*2)\n",
        "    x = MaxPool1D(2)(x)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "\n",
        "    x = block(x,filters*4)\n",
        "    x = MaxPool1D(2)(x)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "\n",
        "    x = block(x,filters*8)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "\n",
        "    return Model(inputs=[M,P],outputs=x)\n",
        "\n",
        "\n",
        "def build_DD_Net(frame_l=32,joint_n=22,joint_d=3,feat_d=231,clc_num=14,filters=16):\n",
        "    M = Input(name='M', shape=(frame_l,feat_d))\n",
        "    P = Input(name='P', shape=(frame_l,joint_n,joint_d))\n",
        "\n",
        "    FM = build_FM(frame_l,joint_n,joint_d,feat_d,filters)\n",
        "\n",
        "    x = FM([M,P])\n",
        "\n",
        "    x = GlobalMaxPool1D()(x)\n",
        "\n",
        "    x = d1D(x,128)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = d1D(x,128)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(clc_num, activation='softmax')(x)\n",
        "\n",
        "    ######################Self-supervised part\n",
        "    model = Model(inputs=[M,P],outputs=x)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "y8J0YBi3xf7r",
        "outputId": "fe2f399f-f485-4713-daaa-e4f73a3d89be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ M (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ P (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,740,160</span> │ M[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], P[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_max_pooling1d      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ functional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ global_max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_15            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_16            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,806</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ M (\u001b[38;5;33mInputLayer\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m231\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ P (\u001b[38;5;33mInputLayer\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │      \u001b[38;5;34m1,740,160\u001b[0m │ M[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], P[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_max_pooling1d      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ functional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m65,536\u001b[0m │ global_max_pooling1d[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_15            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m16,384\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_16            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │          \u001b[38;5;34m1,806\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,824,910</span> (6.96 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,824,910\u001b[0m (6.96 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,819,278</span> (6.94 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,819,278\u001b[0m (6.94 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> (22.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,632\u001b[0m (22.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "DD_Net = build_DD_Net(C.frame_l,C.joint_n,C.joint_d,C.feat_d,C.clc_coarse,C.filters)\n",
        "DD_Net.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "428x7yhRxyjR"
      },
      "source": [
        "\n",
        "4. Load dataset (download GT_train_1.pkl and  GT_test_1.pkl from github )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPxB--e6UkeI",
        "outputId": "c704fc01-c2b0-4140-e167-4a0efdd21846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-10 18:39:33--  https://github.com/fandulu/DD-Net/archive/master.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/fandulu/DD-Net/zip/refs/heads/master [following]\n",
            "--2024-12-10 18:39:33--  https://codeload.github.com/fandulu/DD-Net/zip/refs/heads/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [         <=>        ]  79.09M  14.7MB/s    in 5.4s    \n",
            "\n",
            "2024-12-10 18:39:38 (14.7 MB/s) - ‘master.zip’ saved [82934337]\n",
            "\n",
            "Archive:  master.zip\n",
            "f26a9994b0bafc41096fa269eab89c2757d71499\n",
            "   creating: DD-Net-master/\n",
            "  inflating: DD-Net-master/.gitignore  \n",
            "   creating: DD-Net-master/JHMDB/\n",
            "  inflating: DD-Net-master/JHMDB/README.md  \n",
            "  inflating: DD-Net-master/JHMDB/jhmdb_1D_heavy.ipynb  \n",
            "  inflating: DD-Net-master/JHMDB/jhmdb_1D_lite.ipynb  \n",
            "  inflating: DD-Net-master/JHMDB/jhmdb_1D_middle.ipynb  \n",
            "  inflating: DD-Net-master/JHMDB/jhmdb_data_preprocessing.ipynb  \n",
            "  inflating: DD-Net-master/JHMDB/utils.py  \n",
            "   creating: DD-Net-master/JHMDB/weights/\n",
            " extracting: DD-Net-master/JHMDB/weights/__init__.py  \n",
            "  inflating: DD-Net-master/LICENSE   \n",
            "  inflating: DD-Net-master/README.md  \n",
            "   creating: DD-Net-master/SHREC/\n",
            "  inflating: DD-Net-master/SHREC/README.md  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_coarse_1D_heavy.ipynb  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_coarse_1D_lite.ipynb  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_data_preprocessing.ipynb  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_fine_1D_heavy.ipynb  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_fine_1D_lite.ipynb  \n",
            "   creating: DD-Net-master/SHREC/images/\n",
            "  inflating: DD-Net-master/SHREC/images/SHREC_14.png  \n",
            "  inflating: DD-Net-master/SHREC/images/SHREC_28.png  \n",
            "  inflating: DD-Net-master/SHREC/utils.py  \n",
            "   creating: DD-Net-master/SHREC/weights/\n",
            " extracting: DD-Net-master/SHREC/weights/.gitkeep  \n",
            " extracting: DD-Net-master/SHREC/weights/__init__.py  \n",
            "   creating: DD-Net-master/data/\n",
            "   creating: DD-Net-master/data/JHMDB/\n",
            "  inflating: DD-Net-master/data/JHMDB/GT_test_1.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_test_2.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_test_3.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_train_1.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_train_2.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_train_3.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/joint_positions.zip  \n",
            "  inflating: DD-Net-master/data/JHMDB/splits.zip  \n",
            "   creating: DD-Net-master/data/SHREC/\n",
            " extracting: DD-Net-master/data/SHREC/__init__.py  \n",
            "  inflating: DD-Net-master/data/SHREC/test.pickle  \n",
            "  inflating: DD-Net-master/data/SHREC/test.pkl  \n",
            "  inflating: DD-Net-master/data/SHREC/train.pickle  \n",
            "  inflating: DD-Net-master/data/SHREC/train.pkl  \n",
            "   creating: DD-Net-master/mics/\n",
            " extracting: DD-Net-master/mics/__init__.py  \n",
            "  inflating: DD-Net-master/mics/demo.png  \n",
            "  inflating: DD-Net-master/mics/look.gif  \n",
            "  inflating: DD-Net-master/mics/paper.png  \n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/fandulu/DD-Net/archive/master.zip\n",
        "!unzip master.zip\n",
        "!rm master.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kbObgzuHD6f"
      },
      "source": [
        "5. Running codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baR9WIVLye-0",
        "outputId": "0c1b10cf-d31c-4b6d-c0ad-1f24f566f69a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1960 [00:00<?, ?it/s]<ipython-input-10-0acc17230e16>:23: DeprecationWarning: Please import `zoom` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
            "  p_new[:,m,n] = inter.zoom(p[:,m,n],target_l/l)[:target_l]\n",
            "100%|██████████| 1960/1960 [00:30<00:00, 64.01it/s]\n"
          ]
        }
      ],
      "source": [
        "Train = pickle.load(open(\"/content/DD-Net-master/data/SHREC/train.pkl\", \"rb\"))\n",
        "Test = pickle.load(open(\"/content/DD-Net-master/data/SHREC/test.pkl\", \"rb\"))\n",
        "\n",
        "X_0 = []\n",
        "X_1 = []\n",
        "Y = []\n",
        "for i in tqdm(range(len(Train['pose']))):\n",
        "    p = np.copy(Train['pose'][i]).reshape([-1,22,3])\n",
        "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
        "    p = normlize_range(p)\n",
        "\n",
        "    label = np.zeros(C.clc_coarse)\n",
        "    label[Train['coarse_label'][i]-1] = 1\n",
        "\n",
        "    M = get_CG(p,C)\n",
        "\n",
        "    X_0.append(M)\n",
        "    X_1.append(p)\n",
        "    Y.append(label)\n",
        "\n",
        "X_0 = np.stack(X_0)\n",
        "X_1 = np.stack(X_1)\n",
        "Y = np.stack(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgD_qxkmihlj",
        "outputId": "19f6cab3-ad42-49ec-9cbe-10960646215b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/840 [00:00<?, ?it/s]<ipython-input-10-0acc17230e16>:23: DeprecationWarning: Please import `zoom` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
            "  p_new[:,m,n] = inter.zoom(p[:,m,n],target_l/l)[:target_l]\n",
            "100%|██████████| 840/840 [00:20<00:00, 40.90it/s]\n"
          ]
        }
      ],
      "source": [
        "X_test_0 = []\n",
        "X_test_1 = []\n",
        "Y_test = []\n",
        "for i in tqdm(range(len(Test['pose']))):\n",
        "    p = np.copy(Test['pose'][i]).reshape([-1,22,3])\n",
        "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
        "    p = normlize_range(p)\n",
        "\n",
        "    label = np.zeros(C.clc_coarse)\n",
        "    label[Test['coarse_label'][i]-1] = 1\n",
        "\n",
        "    M = get_CG(p,C)\n",
        "\n",
        "    X_test_0.append(M)\n",
        "    X_test_1.append(p)\n",
        "    Y_test.append(label)\n",
        "\n",
        "X_test_0 = np.stack(X_test_0)\n",
        "X_test_1 = np.stack(X_test_1)\n",
        "Y_test = np.stack(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRwpfpB9zrB7",
        "outputId": "8fceaab5-fa66-4d57-eaca-a522a3eb825c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25s/step - accuracy: 0.0679 - loss: 3.4735 - val_accuracy: 0.0690 - val_loss: 2.6388 - learning_rate: 1.0000e-04\n",
            "Epoch 2/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.0750 - loss: 3.3312 - val_accuracy: 0.0750 - val_loss: 2.6386 - learning_rate: 1.0000e-04\n",
            "Epoch 3/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.0837 - loss: 3.2563 - val_accuracy: 0.0869 - val_loss: 2.6386 - learning_rate: 1.0000e-04\n",
            "Epoch 4/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.0918 - loss: 3.1509 - val_accuracy: 0.0976 - val_loss: 2.6386 - learning_rate: 1.0000e-04\n",
            "Epoch 5/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.0964 - loss: 3.1208 - val_accuracy: 0.0762 - val_loss: 2.6386 - learning_rate: 1.0000e-04\n",
            "Epoch 6/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.1224 - loss: 2.9545 - val_accuracy: 0.0845 - val_loss: 2.6386 - learning_rate: 1.0000e-04\n",
            "Epoch 7/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.1168 - loss: 2.9570 - val_accuracy: 0.0810 - val_loss: 2.6387 - learning_rate: 1.0000e-04\n",
            "Epoch 8/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.1327 - loss: 2.8623 - val_accuracy: 0.0810 - val_loss: 2.6388 - learning_rate: 1.0000e-04\n",
            "Epoch 9/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.1561 - loss: 2.7700 - val_accuracy: 0.0810 - val_loss: 2.6390 - learning_rate: 1.0000e-04\n",
            "Epoch 10/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.1393 - loss: 2.8134 - val_accuracy: 0.0810 - val_loss: 2.6392 - learning_rate: 1.0000e-04\n",
            "Epoch 11/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.1617 - loss: 2.7331 - val_accuracy: 0.0810 - val_loss: 2.6395 - learning_rate: 1.0000e-04\n",
            "Epoch 12/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.1510 - loss: 2.7439 - val_accuracy: 0.0810 - val_loss: 2.6398 - learning_rate: 1.0000e-04\n",
            "Epoch 13/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.1607 - loss: 2.7440 - val_accuracy: 0.0810 - val_loss: 2.6402 - learning_rate: 1.0000e-04\n",
            "Epoch 14/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.1811 - loss: 2.5924 - val_accuracy: 0.0810 - val_loss: 2.6407 - learning_rate: 1.0000e-04\n",
            "Epoch 15/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.1934 - loss: 2.6132 - val_accuracy: 0.0810 - val_loss: 2.6413 - learning_rate: 1.0000e-04\n",
            "Epoch 16/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.1847 - loss: 2.5905 - val_accuracy: 0.0810 - val_loss: 2.6419 - learning_rate: 1.0000e-04\n",
            "Epoch 17/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.1949 - loss: 2.5793 - val_accuracy: 0.0810 - val_loss: 2.6427 - learning_rate: 1.0000e-04\n",
            "Epoch 18/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.1944 - loss: 2.5367 - val_accuracy: 0.0810 - val_loss: 2.6435 - learning_rate: 1.0000e-04\n",
            "Epoch 19/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.2102 - loss: 2.5233 - val_accuracy: 0.0810 - val_loss: 2.6444 - learning_rate: 1.0000e-04\n",
            "Epoch 20/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.1867 - loss: 2.5096 - val_accuracy: 0.0810 - val_loss: 2.6453 - learning_rate: 1.0000e-04\n",
            "Epoch 21/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.2311 - loss: 2.3965 - val_accuracy: 0.0810 - val_loss: 2.6464 - learning_rate: 1.0000e-04\n",
            "Epoch 22/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.2316 - loss: 2.3563 - val_accuracy: 0.0810 - val_loss: 2.6476 - learning_rate: 1.0000e-04\n",
            "Epoch 23/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.2321 - loss: 2.3930 - val_accuracy: 0.0810 - val_loss: 2.6488 - learning_rate: 1.0000e-04\n",
            "Epoch 24/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.2372 - loss: 2.3834 - val_accuracy: 0.0810 - val_loss: 2.6500 - learning_rate: 1.0000e-04\n",
            "Epoch 25/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.2597 - loss: 2.3182 - val_accuracy: 0.0810 - val_loss: 2.6513 - learning_rate: 1.0000e-04\n",
            "Epoch 26/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.2730 - loss: 2.2842 - val_accuracy: 0.0810 - val_loss: 2.6527 - learning_rate: 1.0000e-04\n",
            "Epoch 27/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.2811 - loss: 2.2324 - val_accuracy: 0.0810 - val_loss: 2.6541 - learning_rate: 1.0000e-04\n",
            "Epoch 28/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.2832 - loss: 2.2177 - val_accuracy: 0.0810 - val_loss: 2.6556 - learning_rate: 1.0000e-04\n",
            "Epoch 29/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.2872 - loss: 2.1843 - val_accuracy: 0.0786 - val_loss: 2.6572 - learning_rate: 1.0000e-04\n",
            "Epoch 30/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.3102 - loss: 2.1373 - val_accuracy: 0.0714 - val_loss: 2.6588 - learning_rate: 1.0000e-04\n",
            "Epoch 31/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.3061 - loss: 2.1611 - val_accuracy: 0.0643 - val_loss: 2.6605 - learning_rate: 1.0000e-04\n",
            "Epoch 32/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.3143 - loss: 2.1225 - val_accuracy: 0.0667 - val_loss: 2.6622 - learning_rate: 1.0000e-04\n",
            "Epoch 33/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.3357 - loss: 2.0848 - val_accuracy: 0.0655 - val_loss: 2.6639 - learning_rate: 1.0000e-04\n",
            "Epoch 34/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.3434 - loss: 2.0574 - val_accuracy: 0.0679 - val_loss: 2.6657 - learning_rate: 1.0000e-04\n",
            "Epoch 35/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.3485 - loss: 2.0448 - val_accuracy: 0.0714 - val_loss: 2.6676 - learning_rate: 1.0000e-04\n",
            "Epoch 36/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.3383 - loss: 2.0466 - val_accuracy: 0.0786 - val_loss: 2.6695 - learning_rate: 1.0000e-04\n",
            "Epoch 37/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.3378 - loss: 2.0756 - val_accuracy: 0.0976 - val_loss: 2.6714 - learning_rate: 1.0000e-04\n",
            "Epoch 38/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.3811 - loss: 1.9623 - val_accuracy: 0.0905 - val_loss: 2.6733 - learning_rate: 1.0000e-04\n",
            "Epoch 39/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.3934 - loss: 1.9008 - val_accuracy: 0.0750 - val_loss: 2.6753 - learning_rate: 1.0000e-04\n",
            "Epoch 40/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.3821 - loss: 1.9154 - val_accuracy: 0.0619 - val_loss: 2.6775 - learning_rate: 1.0000e-04\n",
            "Epoch 41/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.4036 - loss: 1.8609 - val_accuracy: 0.0607 - val_loss: 2.6796 - learning_rate: 1.0000e-04\n",
            "Epoch 42/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.4056 - loss: 1.8710 - val_accuracy: 0.0607 - val_loss: 2.6817 - learning_rate: 1.0000e-04\n",
            "Epoch 43/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.4296 - loss: 1.8246 - val_accuracy: 0.0607 - val_loss: 2.6838 - learning_rate: 1.0000e-04\n",
            "Epoch 44/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.4168 - loss: 1.8187 - val_accuracy: 0.0607 - val_loss: 2.6860 - learning_rate: 1.0000e-04\n",
            "Epoch 45/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.4383 - loss: 1.7675 - val_accuracy: 0.0607 - val_loss: 2.6883 - learning_rate: 1.0000e-04\n",
            "Epoch 46/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.4199 - loss: 1.7876 - val_accuracy: 0.0607 - val_loss: 2.6907 - learning_rate: 1.0000e-04\n",
            "Epoch 47/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.4520 - loss: 1.7313 - val_accuracy: 0.0607 - val_loss: 2.6932 - learning_rate: 1.0000e-04\n",
            "Epoch 48/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.4485 - loss: 1.7567 - val_accuracy: 0.0607 - val_loss: 2.6957 - learning_rate: 1.0000e-04\n",
            "Epoch 49/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.4689 - loss: 1.6958 - val_accuracy: 0.0607 - val_loss: 2.6982 - learning_rate: 1.0000e-04\n",
            "Epoch 50/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.4857 - loss: 1.6376 - val_accuracy: 0.0607 - val_loss: 2.7010 - learning_rate: 1.0000e-04\n",
            "Epoch 51/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.4791 - loss: 1.6454 - val_accuracy: 0.0607 - val_loss: 2.7038 - learning_rate: 1.0000e-04\n",
            "Epoch 52/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.4903 - loss: 1.6421 - val_accuracy: 0.0607 - val_loss: 2.7066 - learning_rate: 1.0000e-04\n",
            "Epoch 53/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5041 - loss: 1.5968 - val_accuracy: 0.0607 - val_loss: 2.7094 - learning_rate: 1.0000e-04\n",
            "Epoch 54/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5097 - loss: 1.5617 - val_accuracy: 0.0607 - val_loss: 2.7123 - learning_rate: 1.0000e-04\n",
            "Epoch 55/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5122 - loss: 1.5601 - val_accuracy: 0.0607 - val_loss: 2.7153 - learning_rate: 1.0000e-04\n",
            "Epoch 56/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.5194 - loss: 1.5424 - val_accuracy: 0.0607 - val_loss: 2.7185 - learning_rate: 1.0000e-04\n",
            "Epoch 57/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.5449 - loss: 1.4976 - val_accuracy: 0.0607 - val_loss: 2.7217 - learning_rate: 1.0000e-04\n",
            "Epoch 58/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5337 - loss: 1.5113 - val_accuracy: 0.0643 - val_loss: 2.7249 - learning_rate: 1.0000e-04\n",
            "Epoch 59/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5459 - loss: 1.4471 - val_accuracy: 0.0702 - val_loss: 2.7284 - learning_rate: 1.0000e-04\n",
            "Epoch 60/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5485 - loss: 1.4690 - val_accuracy: 0.0774 - val_loss: 2.7319 - learning_rate: 1.0000e-04\n",
            "Epoch 61/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5622 - loss: 1.4098 - val_accuracy: 0.0893 - val_loss: 2.7354 - learning_rate: 1.0000e-04\n",
            "Epoch 62/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5719 - loss: 1.4209 - val_accuracy: 0.0940 - val_loss: 2.7392 - learning_rate: 1.0000e-04\n",
            "Epoch 63/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5827 - loss: 1.3965 - val_accuracy: 0.1012 - val_loss: 2.7429 - learning_rate: 1.0000e-04\n",
            "Epoch 64/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5918 - loss: 1.3522 - val_accuracy: 0.1071 - val_loss: 2.7468 - learning_rate: 1.0000e-04\n",
            "Epoch 65/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5786 - loss: 1.3935 - val_accuracy: 0.1071 - val_loss: 2.7507 - learning_rate: 1.0000e-04\n",
            "Epoch 66/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.6122 - loss: 1.3027 - val_accuracy: 0.1083 - val_loss: 2.7549 - learning_rate: 1.0000e-04\n",
            "Epoch 67/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.6061 - loss: 1.3048 - val_accuracy: 0.1119 - val_loss: 2.7592 - learning_rate: 1.0000e-04\n",
            "Epoch 68/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.6092 - loss: 1.2795 - val_accuracy: 0.1131 - val_loss: 2.7634 - learning_rate: 1.0000e-04\n",
            "Epoch 69/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.6230 - loss: 1.2658 - val_accuracy: 0.1131 - val_loss: 2.7677 - learning_rate: 1.0000e-04\n",
            "Epoch 70/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.6265 - loss: 1.2583 - val_accuracy: 0.1131 - val_loss: 2.7722 - learning_rate: 1.0000e-04\n",
            "Epoch 71/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.6209 - loss: 1.2561 - val_accuracy: 0.1143 - val_loss: 2.7766 - learning_rate: 1.0000e-04\n",
            "Epoch 72/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.6393 - loss: 1.2350 - val_accuracy: 0.1143 - val_loss: 2.7809 - learning_rate: 1.0000e-04\n",
            "Epoch 73/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.6250 - loss: 1.2475 - val_accuracy: 0.1214 - val_loss: 2.7850 - learning_rate: 1.0000e-04\n",
            "Epoch 74/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.6510 - loss: 1.2137 - val_accuracy: 0.1238 - val_loss: 2.7890 - learning_rate: 1.0000e-04\n",
            "Epoch 75/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.6321 - loss: 1.2349 - val_accuracy: 0.1238 - val_loss: 2.7931 - learning_rate: 1.0000e-04\n",
            "Epoch 76/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.6592 - loss: 1.1747 - val_accuracy: 0.1238 - val_loss: 2.7971 - learning_rate: 1.0000e-04\n",
            "Epoch 77/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.6510 - loss: 1.2031 - val_accuracy: 0.1250 - val_loss: 2.8011 - learning_rate: 1.0000e-04\n",
            "Epoch 78/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.6694 - loss: 1.1660 - val_accuracy: 0.1214 - val_loss: 2.8052 - learning_rate: 1.0000e-04\n",
            "Epoch 79/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.6587 - loss: 1.1626 - val_accuracy: 0.1190 - val_loss: 2.8097 - learning_rate: 1.0000e-04\n",
            "Epoch 80/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.6612 - loss: 1.1558 - val_accuracy: 0.1167 - val_loss: 2.8141 - learning_rate: 1.0000e-04\n",
            "Epoch 81/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.6628 - loss: 1.1380 - val_accuracy: 0.1143 - val_loss: 2.8191 - learning_rate: 1.0000e-04\n",
            "Epoch 82/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.6857 - loss: 1.1212 - val_accuracy: 0.1131 - val_loss: 2.8238 - learning_rate: 1.0000e-04\n",
            "Epoch 83/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.6878 - loss: 1.0974 - val_accuracy: 0.1131 - val_loss: 2.8287 - learning_rate: 1.0000e-04\n",
            "Epoch 84/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.6801 - loss: 1.0840 - val_accuracy: 0.1131 - val_loss: 2.8342 - learning_rate: 1.0000e-04\n",
            "Epoch 85/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.6908 - loss: 1.0741 - val_accuracy: 0.1155 - val_loss: 2.8398 - learning_rate: 1.0000e-04\n",
            "Epoch 86/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.6959 - loss: 1.0575 - val_accuracy: 0.1202 - val_loss: 2.8456 - learning_rate: 1.0000e-04\n",
            "Epoch 87/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.7031 - loss: 1.0473 - val_accuracy: 0.1214 - val_loss: 2.8513 - learning_rate: 1.0000e-04\n",
            "Epoch 88/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.7061 - loss: 1.0617 - val_accuracy: 0.1238 - val_loss: 2.8569 - learning_rate: 1.0000e-04\n",
            "Epoch 89/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7163 - loss: 1.0144 - val_accuracy: 0.1238 - val_loss: 2.8624 - learning_rate: 1.0000e-04\n",
            "Epoch 90/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.7071 - loss: 1.0307 - val_accuracy: 0.1238 - val_loss: 2.8679 - learning_rate: 1.0000e-04\n",
            "Epoch 91/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.7128 - loss: 0.9959 - val_accuracy: 0.1238 - val_loss: 2.8739 - learning_rate: 1.0000e-04\n",
            "Epoch 92/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.7245 - loss: 0.9825 - val_accuracy: 0.1238 - val_loss: 2.8799 - learning_rate: 1.0000e-04\n",
            "Epoch 93/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.7362 - loss: 0.9665 - val_accuracy: 0.1238 - val_loss: 2.8861 - learning_rate: 1.0000e-04\n",
            "Epoch 94/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.7199 - loss: 0.9748 - val_accuracy: 0.1238 - val_loss: 2.8925 - learning_rate: 1.0000e-04\n",
            "Epoch 95/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.7378 - loss: 0.9883 - val_accuracy: 0.1238 - val_loss: 2.8993 - learning_rate: 1.0000e-04\n",
            "Epoch 96/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7224 - loss: 0.9624 - val_accuracy: 0.1238 - val_loss: 2.9064 - learning_rate: 1.0000e-04\n",
            "Epoch 97/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.7520 - loss: 0.9272 - val_accuracy: 0.1238 - val_loss: 2.9135 - learning_rate: 1.0000e-04\n",
            "Epoch 98/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7577 - loss: 0.9285 - val_accuracy: 0.1238 - val_loss: 2.9204 - learning_rate: 1.0000e-04\n",
            "Epoch 99/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.7418 - loss: 0.9256 - val_accuracy: 0.1238 - val_loss: 2.9274 - learning_rate: 1.0000e-04\n",
            "Epoch 100/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.7597 - loss: 0.8993 - val_accuracy: 0.1238 - val_loss: 2.9350 - learning_rate: 1.0000e-04\n",
            "Epoch 101/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7556 - loss: 0.8875 - val_accuracy: 0.1238 - val_loss: 2.9424 - learning_rate: 1.0000e-04\n",
            "Epoch 102/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.7378 - loss: 0.9359 - val_accuracy: 0.1238 - val_loss: 2.9496 - learning_rate: 1.0000e-04\n",
            "Epoch 103/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7750 - loss: 0.8781 - val_accuracy: 0.1238 - val_loss: 2.9562 - learning_rate: 1.0000e-04\n",
            "Epoch 104/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.7536 - loss: 0.8911 - val_accuracy: 0.1238 - val_loss: 2.9629 - learning_rate: 1.0000e-04\n",
            "Epoch 105/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.7719 - loss: 0.8681 - val_accuracy: 0.1238 - val_loss: 2.9697 - learning_rate: 1.0000e-04\n",
            "Epoch 106/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7577 - loss: 0.8668 - val_accuracy: 0.1238 - val_loss: 2.9765 - learning_rate: 1.0000e-04\n",
            "Epoch 107/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7770 - loss: 0.8489 - val_accuracy: 0.1238 - val_loss: 2.9833 - learning_rate: 1.0000e-04\n",
            "Epoch 108/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - accuracy: 0.7878 - loss: 0.8176 - val_accuracy: 0.1238 - val_loss: 2.9901 - learning_rate: 1.0000e-04\n",
            "Epoch 109/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step - accuracy: 0.7740 - loss: 0.8318 - val_accuracy: 0.1238 - val_loss: 2.9963 - learning_rate: 1.0000e-04\n",
            "Epoch 110/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7878 - loss: 0.8254 - val_accuracy: 0.1238 - val_loss: 3.0023 - learning_rate: 1.0000e-04\n",
            "Epoch 111/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.7679 - loss: 0.8245 - val_accuracy: 0.1238 - val_loss: 3.0085 - learning_rate: 1.0000e-04\n",
            "Epoch 112/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.7969 - loss: 0.8097 - val_accuracy: 0.1238 - val_loss: 3.0141 - learning_rate: 1.0000e-04\n",
            "Epoch 113/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.7837 - loss: 0.8129 - val_accuracy: 0.1238 - val_loss: 3.0197 - learning_rate: 1.0000e-04\n",
            "Epoch 114/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.7954 - loss: 0.7909 - val_accuracy: 0.1238 - val_loss: 3.0253 - learning_rate: 1.0000e-04\n",
            "Epoch 115/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.7974 - loss: 0.7717 - val_accuracy: 0.1238 - val_loss: 3.0312 - learning_rate: 1.0000e-04\n",
            "Epoch 116/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7929 - loss: 0.7903 - val_accuracy: 0.1238 - val_loss: 3.0367 - learning_rate: 1.0000e-04\n",
            "Epoch 117/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8015 - loss: 0.7597 - val_accuracy: 0.1238 - val_loss: 3.0415 - learning_rate: 1.0000e-04\n",
            "Epoch 118/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.8031 - loss: 0.7709 - val_accuracy: 0.1238 - val_loss: 3.0458 - learning_rate: 1.0000e-04\n",
            "Epoch 119/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8148 - loss: 0.7427 - val_accuracy: 0.1238 - val_loss: 3.0503 - learning_rate: 1.0000e-04\n",
            "Epoch 120/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8117 - loss: 0.7520 - val_accuracy: 0.1238 - val_loss: 3.0552 - learning_rate: 1.0000e-04\n",
            "Epoch 121/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8097 - loss: 0.7671 - val_accuracy: 0.1238 - val_loss: 3.0603 - learning_rate: 1.0000e-04\n",
            "Epoch 122/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8163 - loss: 0.7356 - val_accuracy: 0.1238 - val_loss: 3.0650 - learning_rate: 1.0000e-04\n",
            "Epoch 123/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8128 - loss: 0.7473 - val_accuracy: 0.1226 - val_loss: 3.0693 - learning_rate: 1.0000e-04\n",
            "Epoch 124/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8189 - loss: 0.7458 - val_accuracy: 0.1214 - val_loss: 3.0747 - learning_rate: 1.0000e-04\n",
            "Epoch 125/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.8158 - loss: 0.7335 - val_accuracy: 0.1214 - val_loss: 3.0803 - learning_rate: 1.0000e-04\n",
            "Epoch 126/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.8107 - loss: 0.7413 - val_accuracy: 0.1202 - val_loss: 3.0867 - learning_rate: 1.0000e-04\n",
            "Epoch 127/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8296 - loss: 0.6937 - val_accuracy: 0.1202 - val_loss: 3.0935 - learning_rate: 1.0000e-04\n",
            "Epoch 128/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8194 - loss: 0.7061 - val_accuracy: 0.1202 - val_loss: 3.1008 - learning_rate: 1.0000e-04\n",
            "Epoch 129/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8281 - loss: 0.7080 - val_accuracy: 0.1167 - val_loss: 3.1086 - learning_rate: 1.0000e-04\n",
            "Epoch 130/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8311 - loss: 0.6747 - val_accuracy: 0.1167 - val_loss: 3.1170 - learning_rate: 1.0000e-04\n",
            "Epoch 131/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8281 - loss: 0.6883 - val_accuracy: 0.1155 - val_loss: 3.1247 - learning_rate: 1.0000e-04\n",
            "Epoch 132/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8423 - loss: 0.6609 - val_accuracy: 0.1155 - val_loss: 3.1326 - learning_rate: 1.0000e-04\n",
            "Epoch 133/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8352 - loss: 0.6702 - val_accuracy: 0.1167 - val_loss: 3.1399 - learning_rate: 1.0000e-04\n",
            "Epoch 134/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8301 - loss: 0.6882 - val_accuracy: 0.1167 - val_loss: 3.1463 - learning_rate: 1.0000e-04\n",
            "Epoch 135/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8321 - loss: 0.6835 - val_accuracy: 0.1167 - val_loss: 3.1521 - learning_rate: 1.0000e-04\n",
            "Epoch 136/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8311 - loss: 0.6584 - val_accuracy: 0.1179 - val_loss: 3.1572 - learning_rate: 1.0000e-04\n",
            "Epoch 137/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8393 - loss: 0.6650 - val_accuracy: 0.1190 - val_loss: 3.1616 - learning_rate: 1.0000e-04\n",
            "Epoch 138/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8418 - loss: 0.6567 - val_accuracy: 0.1202 - val_loss: 3.1659 - learning_rate: 1.0000e-04\n",
            "Epoch 139/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8378 - loss: 0.6529 - val_accuracy: 0.1226 - val_loss: 3.1702 - learning_rate: 1.0000e-04\n",
            "Epoch 140/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8526 - loss: 0.6414 - val_accuracy: 0.1226 - val_loss: 3.1742 - learning_rate: 1.0000e-04\n",
            "Epoch 141/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8378 - loss: 0.6523 - val_accuracy: 0.1226 - val_loss: 3.1770 - learning_rate: 1.0000e-04\n",
            "Epoch 142/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8352 - loss: 0.6381 - val_accuracy: 0.1226 - val_loss: 3.1798 - learning_rate: 1.0000e-04\n",
            "Epoch 143/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8561 - loss: 0.6144 - val_accuracy: 0.1238 - val_loss: 3.1825 - learning_rate: 1.0000e-04\n",
            "Epoch 144/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8561 - loss: 0.6075 - val_accuracy: 0.1238 - val_loss: 3.1856 - learning_rate: 1.0000e-04\n",
            "Epoch 145/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8531 - loss: 0.6176 - val_accuracy: 0.1238 - val_loss: 3.1885 - learning_rate: 1.0000e-04\n",
            "Epoch 146/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8474 - loss: 0.6245 - val_accuracy: 0.1238 - val_loss: 3.1919 - learning_rate: 1.0000e-04\n",
            "Epoch 147/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8607 - loss: 0.5918 - val_accuracy: 0.1238 - val_loss: 3.1951 - learning_rate: 1.0000e-04\n",
            "Epoch 148/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8638 - loss: 0.5955 - val_accuracy: 0.1238 - val_loss: 3.1976 - learning_rate: 1.0000e-04\n",
            "Epoch 149/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8689 - loss: 0.5892 - val_accuracy: 0.1238 - val_loss: 3.1995 - learning_rate: 1.0000e-04\n",
            "Epoch 150/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8673 - loss: 0.5834 - val_accuracy: 0.1238 - val_loss: 3.2030 - learning_rate: 1.0000e-04\n",
            "Epoch 151/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8607 - loss: 0.5858 - val_accuracy: 0.1238 - val_loss: 3.2064 - learning_rate: 1.0000e-04\n",
            "Epoch 152/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8791 - loss: 0.5584 - val_accuracy: 0.1238 - val_loss: 3.2104 - learning_rate: 1.0000e-04\n",
            "Epoch 153/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8776 - loss: 0.5489 - val_accuracy: 0.1226 - val_loss: 3.2147 - learning_rate: 1.0000e-04\n",
            "Epoch 154/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8801 - loss: 0.5684 - val_accuracy: 0.1226 - val_loss: 3.2182 - learning_rate: 1.0000e-04\n",
            "Epoch 155/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8663 - loss: 0.5752 - val_accuracy: 0.1226 - val_loss: 3.2218 - learning_rate: 1.0000e-04\n",
            "Epoch 156/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8724 - loss: 0.5767 - val_accuracy: 0.1226 - val_loss: 3.2267 - learning_rate: 1.0000e-04\n",
            "Epoch 157/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.8638 - loss: 0.5656 - val_accuracy: 0.1214 - val_loss: 3.2317 - learning_rate: 1.0000e-04\n",
            "Epoch 158/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step - accuracy: 0.8612 - loss: 0.5949 - val_accuracy: 0.1190 - val_loss: 3.2376 - learning_rate: 1.0000e-04\n",
            "Epoch 159/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8776 - loss: 0.5556 - val_accuracy: 0.1190 - val_loss: 3.2406 - learning_rate: 5.0000e-05\n",
            "Epoch 160/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8786 - loss: 0.5420 - val_accuracy: 0.1190 - val_loss: 3.2431 - learning_rate: 5.0000e-05\n",
            "Epoch 161/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8883 - loss: 0.5284 - val_accuracy: 0.1190 - val_loss: 3.2461 - learning_rate: 5.0000e-05\n",
            "Epoch 162/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8811 - loss: 0.5448 - val_accuracy: 0.1190 - val_loss: 3.2481 - learning_rate: 5.0000e-05\n",
            "Epoch 163/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8776 - loss: 0.5362 - val_accuracy: 0.1190 - val_loss: 3.2500 - learning_rate: 5.0000e-05\n",
            "Epoch 164/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8648 - loss: 0.5584 - val_accuracy: 0.1190 - val_loss: 3.2512 - learning_rate: 5.0000e-05\n",
            "Epoch 165/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8765 - loss: 0.5440 - val_accuracy: 0.1190 - val_loss: 3.2528 - learning_rate: 5.0000e-05\n",
            "Epoch 166/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8699 - loss: 0.5484 - val_accuracy: 0.1190 - val_loss: 3.2548 - learning_rate: 5.0000e-05\n",
            "Epoch 167/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8883 - loss: 0.5258 - val_accuracy: 0.1214 - val_loss: 3.2570 - learning_rate: 5.0000e-05\n",
            "Epoch 168/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8786 - loss: 0.5430 - val_accuracy: 0.1214 - val_loss: 3.2591 - learning_rate: 5.0000e-05\n",
            "Epoch 169/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8867 - loss: 0.5269 - val_accuracy: 0.1226 - val_loss: 3.2619 - learning_rate: 5.0000e-05\n",
            "Epoch 170/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8867 - loss: 0.5360 - val_accuracy: 0.1226 - val_loss: 3.2650 - learning_rate: 5.0000e-05\n",
            "Epoch 171/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8724 - loss: 0.5395 - val_accuracy: 0.1226 - val_loss: 3.2683 - learning_rate: 5.0000e-05\n",
            "Epoch 172/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8878 - loss: 0.5139 - val_accuracy: 0.1226 - val_loss: 3.2712 - learning_rate: 5.0000e-05\n",
            "Epoch 173/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8704 - loss: 0.5415 - val_accuracy: 0.1226 - val_loss: 3.2734 - learning_rate: 5.0000e-05\n",
            "Epoch 174/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8923 - loss: 0.5100 - val_accuracy: 0.1226 - val_loss: 3.2744 - learning_rate: 5.0000e-05\n",
            "Epoch 175/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8908 - loss: 0.5264 - val_accuracy: 0.1226 - val_loss: 3.2749 - learning_rate: 5.0000e-05\n",
            "Epoch 176/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8821 - loss: 0.5249 - val_accuracy: 0.1238 - val_loss: 3.2762 - learning_rate: 5.0000e-05\n",
            "Epoch 177/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8893 - loss: 0.4981 - val_accuracy: 0.1238 - val_loss: 3.2774 - learning_rate: 5.0000e-05\n",
            "Epoch 178/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8745 - loss: 0.5287 - val_accuracy: 0.1238 - val_loss: 3.2784 - learning_rate: 5.0000e-05\n",
            "Epoch 179/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8929 - loss: 0.5165 - val_accuracy: 0.1238 - val_loss: 3.2793 - learning_rate: 5.0000e-05\n",
            "Epoch 180/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8816 - loss: 0.5084 - val_accuracy: 0.1238 - val_loss: 3.2812 - learning_rate: 5.0000e-05\n",
            "Epoch 181/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8832 - loss: 0.5267 - val_accuracy: 0.1238 - val_loss: 3.2820 - learning_rate: 5.0000e-05\n",
            "Epoch 182/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8724 - loss: 0.5410 - val_accuracy: 0.1238 - val_loss: 3.2824 - learning_rate: 5.0000e-05\n",
            "Epoch 183/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8923 - loss: 0.4904 - val_accuracy: 0.1238 - val_loss: 3.2823 - learning_rate: 2.5000e-05\n",
            "Epoch 184/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8923 - loss: 0.4916 - val_accuracy: 0.1238 - val_loss: 3.2827 - learning_rate: 2.5000e-05\n",
            "Epoch 185/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8949 - loss: 0.4799 - val_accuracy: 0.1238 - val_loss: 3.2830 - learning_rate: 2.5000e-05\n",
            "Epoch 186/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8827 - loss: 0.5002 - val_accuracy: 0.1238 - val_loss: 3.2830 - learning_rate: 2.5000e-05\n",
            "Epoch 187/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8862 - loss: 0.5077 - val_accuracy: 0.1238 - val_loss: 3.2834 - learning_rate: 2.5000e-05\n",
            "Epoch 188/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8918 - loss: 0.4952 - val_accuracy: 0.1238 - val_loss: 3.2835 - learning_rate: 2.5000e-05\n",
            "Epoch 189/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8898 - loss: 0.5071 - val_accuracy: 0.1238 - val_loss: 3.2832 - learning_rate: 2.5000e-05\n",
            "Epoch 190/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8949 - loss: 0.4994 - val_accuracy: 0.1238 - val_loss: 3.2827 - learning_rate: 2.5000e-05\n",
            "Epoch 191/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8908 - loss: 0.5012 - val_accuracy: 0.1238 - val_loss: 3.2820 - learning_rate: 2.5000e-05\n",
            "Epoch 192/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8964 - loss: 0.5103 - val_accuracy: 0.1238 - val_loss: 3.2809 - learning_rate: 1.2500e-05\n",
            "Epoch 193/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8888 - loss: 0.5059 - val_accuracy: 0.1238 - val_loss: 3.2796 - learning_rate: 1.2500e-05\n",
            "Epoch 194/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8893 - loss: 0.5027 - val_accuracy: 0.1238 - val_loss: 3.2783 - learning_rate: 1.2500e-05\n",
            "Epoch 195/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8852 - loss: 0.5063 - val_accuracy: 0.1238 - val_loss: 3.2768 - learning_rate: 1.2500e-05\n",
            "Epoch 196/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8949 - loss: 0.5053 - val_accuracy: 0.1238 - val_loss: 3.2754 - learning_rate: 1.2500e-05\n",
            "Epoch 197/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8944 - loss: 0.4902 - val_accuracy: 0.1238 - val_loss: 3.2738 - learning_rate: 1.2500e-05\n",
            "Epoch 198/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8883 - loss: 0.5090 - val_accuracy: 0.1238 - val_loss: 3.2720 - learning_rate: 1.2500e-05\n",
            "Epoch 199/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8929 - loss: 0.4935 - val_accuracy: 0.1238 - val_loss: 3.2704 - learning_rate: 1.2500e-05\n",
            "Epoch 200/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8847 - loss: 0.4989 - val_accuracy: 0.1238 - val_loss: 3.2686 - learning_rate: 1.2500e-05\n",
            "Epoch 201/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8918 - loss: 0.4855 - val_accuracy: 0.1238 - val_loss: 3.2669 - learning_rate: 6.2500e-06\n",
            "Epoch 202/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8929 - loss: 0.4868 - val_accuracy: 0.1238 - val_loss: 3.2651 - learning_rate: 6.2500e-06\n",
            "Epoch 203/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9005 - loss: 0.4899 - val_accuracy: 0.1238 - val_loss: 3.2634 - learning_rate: 6.2500e-06\n",
            "Epoch 204/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8878 - loss: 0.4876 - val_accuracy: 0.1238 - val_loss: 3.2614 - learning_rate: 6.2500e-06\n",
            "Epoch 205/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8959 - loss: 0.5009 - val_accuracy: 0.1250 - val_loss: 3.2597 - learning_rate: 6.2500e-06\n",
            "Epoch 206/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8862 - loss: 0.5132 - val_accuracy: 0.1250 - val_loss: 3.2577 - learning_rate: 6.2500e-06\n",
            "Epoch 207/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8980 - loss: 0.4957 - val_accuracy: 0.1250 - val_loss: 3.2557 - learning_rate: 6.2500e-06\n",
            "Epoch 208/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8913 - loss: 0.4963 - val_accuracy: 0.1250 - val_loss: 3.2536 - learning_rate: 6.2500e-06\n",
            "Epoch 209/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8898 - loss: 0.4903 - val_accuracy: 0.1250 - val_loss: 3.2518 - learning_rate: 6.2500e-06\n",
            "Epoch 210/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8918 - loss: 0.4926 - val_accuracy: 0.1250 - val_loss: 3.2496 - learning_rate: 5.0000e-06\n",
            "Epoch 211/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8934 - loss: 0.4926 - val_accuracy: 0.1250 - val_loss: 3.2477 - learning_rate: 5.0000e-06\n",
            "Epoch 212/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8939 - loss: 0.4854 - val_accuracy: 0.1250 - val_loss: 3.2455 - learning_rate: 5.0000e-06\n",
            "Epoch 213/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8949 - loss: 0.4882 - val_accuracy: 0.1250 - val_loss: 3.2433 - learning_rate: 5.0000e-06\n",
            "Epoch 214/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9005 - loss: 0.4839 - val_accuracy: 0.1250 - val_loss: 3.2410 - learning_rate: 5.0000e-06\n",
            "Epoch 215/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8801 - loss: 0.5157 - val_accuracy: 0.1250 - val_loss: 3.2385 - learning_rate: 5.0000e-06\n",
            "Epoch 216/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8842 - loss: 0.4950 - val_accuracy: 0.1250 - val_loss: 3.2363 - learning_rate: 5.0000e-06\n",
            "Epoch 217/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8888 - loss: 0.4836 - val_accuracy: 0.1250 - val_loss: 3.2339 - learning_rate: 5.0000e-06\n",
            "Epoch 218/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8959 - loss: 0.4767 - val_accuracy: 0.1250 - val_loss: 3.2315 - learning_rate: 5.0000e-06\n",
            "Epoch 219/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8888 - loss: 0.4939 - val_accuracy: 0.1250 - val_loss: 3.2294 - learning_rate: 5.0000e-06\n",
            "Epoch 220/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8969 - loss: 0.4839 - val_accuracy: 0.1250 - val_loss: 3.2272 - learning_rate: 5.0000e-06\n",
            "Epoch 221/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8974 - loss: 0.4889 - val_accuracy: 0.1250 - val_loss: 3.2248 - learning_rate: 5.0000e-06\n",
            "Epoch 222/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9005 - loss: 0.4795 - val_accuracy: 0.1250 - val_loss: 3.2221 - learning_rate: 5.0000e-06\n",
            "Epoch 223/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9026 - loss: 0.4743 - val_accuracy: 0.1250 - val_loss: 3.2195 - learning_rate: 5.0000e-06\n",
            "Epoch 224/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8934 - loss: 0.4914 - val_accuracy: 0.1250 - val_loss: 3.2169 - learning_rate: 5.0000e-06\n",
            "Epoch 225/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9010 - loss: 0.4805 - val_accuracy: 0.1250 - val_loss: 3.2140 - learning_rate: 5.0000e-06\n",
            "Epoch 226/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8903 - loss: 0.4988 - val_accuracy: 0.1250 - val_loss: 3.2114 - learning_rate: 5.0000e-06\n",
            "Epoch 227/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8878 - loss: 0.4917 - val_accuracy: 0.1250 - val_loss: 3.2087 - learning_rate: 5.0000e-06\n",
            "Epoch 228/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8969 - loss: 0.4992 - val_accuracy: 0.1250 - val_loss: 3.2060 - learning_rate: 5.0000e-06\n",
            "Epoch 229/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8934 - loss: 0.4910 - val_accuracy: 0.1250 - val_loss: 3.2032 - learning_rate: 5.0000e-06\n",
            "Epoch 230/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8898 - loss: 0.4936 - val_accuracy: 0.1250 - val_loss: 3.2006 - learning_rate: 5.0000e-06\n",
            "Epoch 231/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9005 - loss: 0.4821 - val_accuracy: 0.1250 - val_loss: 3.1976 - learning_rate: 5.0000e-06\n",
            "Epoch 232/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8949 - loss: 0.4971 - val_accuracy: 0.1250 - val_loss: 3.1945 - learning_rate: 5.0000e-06\n",
            "Epoch 233/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9005 - loss: 0.4854 - val_accuracy: 0.1250 - val_loss: 3.1913 - learning_rate: 5.0000e-06\n",
            "Epoch 234/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8944 - loss: 0.4784 - val_accuracy: 0.1250 - val_loss: 3.1880 - learning_rate: 5.0000e-06\n",
            "Epoch 235/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8995 - loss: 0.4904 - val_accuracy: 0.1250 - val_loss: 3.1849 - learning_rate: 5.0000e-06\n",
            "Epoch 236/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8990 - loss: 0.4913 - val_accuracy: 0.1250 - val_loss: 3.1819 - learning_rate: 5.0000e-06\n",
            "Epoch 237/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8862 - loss: 0.5103 - val_accuracy: 0.1250 - val_loss: 3.1789 - learning_rate: 5.0000e-06\n",
            "Epoch 238/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8893 - loss: 0.4985 - val_accuracy: 0.1250 - val_loss: 3.1756 - learning_rate: 5.0000e-06\n",
            "Epoch 239/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8893 - loss: 0.5088 - val_accuracy: 0.1250 - val_loss: 3.1721 - learning_rate: 5.0000e-06\n",
            "Epoch 240/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9010 - loss: 0.4862 - val_accuracy: 0.1250 - val_loss: 3.1686 - learning_rate: 5.0000e-06\n",
            "Epoch 241/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.8898 - loss: 0.4844 - val_accuracy: 0.1250 - val_loss: 3.1650 - learning_rate: 5.0000e-06\n",
            "Epoch 242/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8949 - loss: 0.4901 - val_accuracy: 0.1250 - val_loss: 3.1613 - learning_rate: 5.0000e-06\n",
            "Epoch 243/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8980 - loss: 0.4776 - val_accuracy: 0.1250 - val_loss: 3.1575 - learning_rate: 5.0000e-06\n",
            "Epoch 244/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8893 - loss: 0.4984 - val_accuracy: 0.1250 - val_loss: 3.1538 - learning_rate: 5.0000e-06\n",
            "Epoch 245/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8888 - loss: 0.5027 - val_accuracy: 0.1250 - val_loss: 3.1500 - learning_rate: 5.0000e-06\n",
            "Epoch 246/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8934 - loss: 0.4961 - val_accuracy: 0.1250 - val_loss: 3.1459 - learning_rate: 5.0000e-06\n",
            "Epoch 247/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8929 - loss: 0.4838 - val_accuracy: 0.1250 - val_loss: 3.1422 - learning_rate: 5.0000e-06\n",
            "Epoch 248/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8867 - loss: 0.4965 - val_accuracy: 0.1250 - val_loss: 3.1383 - learning_rate: 5.0000e-06\n",
            "Epoch 249/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8908 - loss: 0.4871 - val_accuracy: 0.1250 - val_loss: 3.1343 - learning_rate: 5.0000e-06\n",
            "Epoch 250/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8903 - loss: 0.5059 - val_accuracy: 0.1250 - val_loss: 3.1303 - learning_rate: 5.0000e-06\n",
            "Epoch 251/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8959 - loss: 0.4873 - val_accuracy: 0.1250 - val_loss: 3.1263 - learning_rate: 5.0000e-06\n",
            "Epoch 252/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8918 - loss: 0.4995 - val_accuracy: 0.1250 - val_loss: 3.1220 - learning_rate: 5.0000e-06\n",
            "Epoch 253/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8847 - loss: 0.4821 - val_accuracy: 0.1250 - val_loss: 3.1179 - learning_rate: 5.0000e-06\n",
            "Epoch 254/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8969 - loss: 0.4912 - val_accuracy: 0.1250 - val_loss: 3.1136 - learning_rate: 5.0000e-06\n",
            "Epoch 255/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8908 - loss: 0.4897 - val_accuracy: 0.1250 - val_loss: 3.1094 - learning_rate: 5.0000e-06\n",
            "Epoch 256/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8949 - loss: 0.4908 - val_accuracy: 0.1250 - val_loss: 3.1051 - learning_rate: 5.0000e-06\n",
            "Epoch 257/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9005 - loss: 0.4746 - val_accuracy: 0.1250 - val_loss: 3.1008 - learning_rate: 5.0000e-06\n",
            "Epoch 258/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8954 - loss: 0.4850 - val_accuracy: 0.1250 - val_loss: 3.0964 - learning_rate: 5.0000e-06\n",
            "Epoch 259/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9015 - loss: 0.4717 - val_accuracy: 0.1250 - val_loss: 3.0918 - learning_rate: 5.0000e-06\n",
            "Epoch 260/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9066 - loss: 0.4742 - val_accuracy: 0.1250 - val_loss: 3.0874 - learning_rate: 5.0000e-06\n",
            "Epoch 261/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9036 - loss: 0.4617 - val_accuracy: 0.1250 - val_loss: 3.0829 - learning_rate: 5.0000e-06\n",
            "Epoch 262/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8811 - loss: 0.5032 - val_accuracy: 0.1250 - val_loss: 3.0782 - learning_rate: 5.0000e-06\n",
            "Epoch 263/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8954 - loss: 0.4868 - val_accuracy: 0.1250 - val_loss: 3.0735 - learning_rate: 5.0000e-06\n",
            "Epoch 264/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8949 - loss: 0.4761 - val_accuracy: 0.1250 - val_loss: 3.0687 - learning_rate: 5.0000e-06\n",
            "Epoch 265/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8985 - loss: 0.4750 - val_accuracy: 0.1250 - val_loss: 3.0638 - learning_rate: 5.0000e-06\n",
            "Epoch 266/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8964 - loss: 0.4981 - val_accuracy: 0.1250 - val_loss: 3.0588 - learning_rate: 5.0000e-06\n",
            "Epoch 267/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8918 - loss: 0.4961 - val_accuracy: 0.1250 - val_loss: 3.0537 - learning_rate: 5.0000e-06\n",
            "Epoch 268/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8980 - loss: 0.4768 - val_accuracy: 0.1250 - val_loss: 3.0488 - learning_rate: 5.0000e-06\n",
            "Epoch 269/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9026 - loss: 0.4775 - val_accuracy: 0.1250 - val_loss: 3.0436 - learning_rate: 5.0000e-06\n",
            "Epoch 270/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8923 - loss: 0.4891 - val_accuracy: 0.1250 - val_loss: 3.0384 - learning_rate: 5.0000e-06\n",
            "Epoch 271/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9056 - loss: 0.4663 - val_accuracy: 0.1250 - val_loss: 3.0332 - learning_rate: 5.0000e-06\n",
            "Epoch 272/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8959 - loss: 0.4797 - val_accuracy: 0.1262 - val_loss: 3.0278 - learning_rate: 5.0000e-06\n",
            "Epoch 273/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8903 - loss: 0.4746 - val_accuracy: 0.1274 - val_loss: 3.0223 - learning_rate: 5.0000e-06\n",
            "Epoch 274/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9010 - loss: 0.4707 - val_accuracy: 0.1274 - val_loss: 3.0169 - learning_rate: 5.0000e-06\n",
            "Epoch 275/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8888 - loss: 0.4911 - val_accuracy: 0.1274 - val_loss: 3.0112 - learning_rate: 5.0000e-06\n",
            "Epoch 276/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8959 - loss: 0.4904 - val_accuracy: 0.1274 - val_loss: 3.0055 - learning_rate: 5.0000e-06\n",
            "Epoch 277/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8959 - loss: 0.4853 - val_accuracy: 0.1274 - val_loss: 2.9996 - learning_rate: 5.0000e-06\n",
            "Epoch 278/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8974 - loss: 0.4864 - val_accuracy: 0.1274 - val_loss: 2.9939 - learning_rate: 5.0000e-06\n",
            "Epoch 279/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8959 - loss: 0.4775 - val_accuracy: 0.1274 - val_loss: 2.9882 - learning_rate: 5.0000e-06\n",
            "Epoch 280/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8903 - loss: 0.4813 - val_accuracy: 0.1274 - val_loss: 2.9825 - learning_rate: 5.0000e-06\n",
            "Epoch 281/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9077 - loss: 0.4569 - val_accuracy: 0.1274 - val_loss: 2.9769 - learning_rate: 5.0000e-06\n",
            "Epoch 282/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8903 - loss: 0.4839 - val_accuracy: 0.1286 - val_loss: 2.9708 - learning_rate: 5.0000e-06\n",
            "Epoch 283/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8857 - loss: 0.4999 - val_accuracy: 0.1310 - val_loss: 2.9648 - learning_rate: 5.0000e-06\n",
            "Epoch 284/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.8990 - loss: 0.4782 - val_accuracy: 0.1321 - val_loss: 2.9588 - learning_rate: 5.0000e-06\n",
            "Epoch 285/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.8888 - loss: 0.4985 - val_accuracy: 0.1321 - val_loss: 2.9523 - learning_rate: 5.0000e-06\n",
            "Epoch 286/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9077 - loss: 0.4617 - val_accuracy: 0.1321 - val_loss: 2.9461 - learning_rate: 5.0000e-06\n",
            "Epoch 287/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8969 - loss: 0.4805 - val_accuracy: 0.1333 - val_loss: 2.9397 - learning_rate: 5.0000e-06\n",
            "Epoch 288/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9020 - loss: 0.4770 - val_accuracy: 0.1333 - val_loss: 2.9335 - learning_rate: 5.0000e-06\n",
            "Epoch 289/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8862 - loss: 0.4842 - val_accuracy: 0.1333 - val_loss: 2.9269 - learning_rate: 5.0000e-06\n",
            "Epoch 290/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8995 - loss: 0.4806 - val_accuracy: 0.1357 - val_loss: 2.9205 - learning_rate: 5.0000e-06\n",
            "Epoch 291/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8995 - loss: 0.4736 - val_accuracy: 0.1369 - val_loss: 2.9139 - learning_rate: 5.0000e-06\n",
            "Epoch 292/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.8908 - loss: 0.4939 - val_accuracy: 0.1369 - val_loss: 2.9074 - learning_rate: 5.0000e-06\n",
            "Epoch 293/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8990 - loss: 0.4790 - val_accuracy: 0.1381 - val_loss: 2.9009 - learning_rate: 5.0000e-06\n",
            "Epoch 294/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8816 - loss: 0.4926 - val_accuracy: 0.1393 - val_loss: 2.8939 - learning_rate: 5.0000e-06\n",
            "Epoch 295/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9010 - loss: 0.4781 - val_accuracy: 0.1405 - val_loss: 2.8872 - learning_rate: 5.0000e-06\n",
            "Epoch 296/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.8969 - loss: 0.4695 - val_accuracy: 0.1405 - val_loss: 2.8803 - learning_rate: 5.0000e-06\n",
            "Epoch 297/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8862 - loss: 0.4900 - val_accuracy: 0.1440 - val_loss: 2.8735 - learning_rate: 5.0000e-06\n",
            "Epoch 298/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9015 - loss: 0.4659 - val_accuracy: 0.1452 - val_loss: 2.8667 - learning_rate: 5.0000e-06\n",
            "Epoch 299/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9010 - loss: 0.4694 - val_accuracy: 0.1452 - val_loss: 2.8596 - learning_rate: 5.0000e-06\n",
            "Epoch 300/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.8883 - loss: 0.4931 - val_accuracy: 0.1476 - val_loss: 2.8524 - learning_rate: 5.0000e-06\n",
            "Epoch 301/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9005 - loss: 0.4990 - val_accuracy: 0.1500 - val_loss: 2.8453 - learning_rate: 5.0000e-06\n",
            "Epoch 302/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8888 - loss: 0.4972 - val_accuracy: 0.1500 - val_loss: 2.8380 - learning_rate: 5.0000e-06\n",
            "Epoch 303/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9015 - loss: 0.4782 - val_accuracy: 0.1524 - val_loss: 2.8305 - learning_rate: 5.0000e-06\n",
            "Epoch 304/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8974 - loss: 0.4808 - val_accuracy: 0.1524 - val_loss: 2.8230 - learning_rate: 5.0000e-06\n",
            "Epoch 305/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9071 - loss: 0.4651 - val_accuracy: 0.1536 - val_loss: 2.8154 - learning_rate: 5.0000e-06\n",
            "Epoch 306/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8878 - loss: 0.5005 - val_accuracy: 0.1560 - val_loss: 2.8078 - learning_rate: 5.0000e-06\n",
            "Epoch 307/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8929 - loss: 0.4834 - val_accuracy: 0.1595 - val_loss: 2.8003 - learning_rate: 5.0000e-06\n",
            "Epoch 308/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8913 - loss: 0.4804 - val_accuracy: 0.1607 - val_loss: 2.7928 - learning_rate: 5.0000e-06\n",
            "Epoch 309/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8913 - loss: 0.4778 - val_accuracy: 0.1607 - val_loss: 2.7851 - learning_rate: 5.0000e-06\n",
            "Epoch 310/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9010 - loss: 0.4772 - val_accuracy: 0.1619 - val_loss: 2.7773 - learning_rate: 5.0000e-06\n",
            "Epoch 311/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8918 - loss: 0.4755 - val_accuracy: 0.1631 - val_loss: 2.7694 - learning_rate: 5.0000e-06\n",
            "Epoch 312/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9036 - loss: 0.4667 - val_accuracy: 0.1631 - val_loss: 2.7618 - learning_rate: 5.0000e-06\n",
            "Epoch 313/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8883 - loss: 0.4855 - val_accuracy: 0.1631 - val_loss: 2.7537 - learning_rate: 5.0000e-06\n",
            "Epoch 314/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8974 - loss: 0.4766 - val_accuracy: 0.1643 - val_loss: 2.7457 - learning_rate: 5.0000e-06\n",
            "Epoch 315/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9026 - loss: 0.4704 - val_accuracy: 0.1679 - val_loss: 2.7376 - learning_rate: 5.0000e-06\n",
            "Epoch 316/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9046 - loss: 0.4628 - val_accuracy: 0.1679 - val_loss: 2.7294 - learning_rate: 5.0000e-06\n",
            "Epoch 317/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8990 - loss: 0.4695 - val_accuracy: 0.1679 - val_loss: 2.7207 - learning_rate: 5.0000e-06\n",
            "Epoch 318/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9020 - loss: 0.4737 - val_accuracy: 0.1702 - val_loss: 2.7122 - learning_rate: 5.0000e-06\n",
            "Epoch 319/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8974 - loss: 0.4672 - val_accuracy: 0.1726 - val_loss: 2.7040 - learning_rate: 5.0000e-06\n",
            "Epoch 320/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8852 - loss: 0.4839 - val_accuracy: 0.1750 - val_loss: 2.6957 - learning_rate: 5.0000e-06\n",
            "Epoch 321/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9061 - loss: 0.4645 - val_accuracy: 0.1762 - val_loss: 2.6871 - learning_rate: 5.0000e-06\n",
            "Epoch 322/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8847 - loss: 0.4784 - val_accuracy: 0.1786 - val_loss: 2.6785 - learning_rate: 5.0000e-06\n",
            "Epoch 323/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8964 - loss: 0.4787 - val_accuracy: 0.1810 - val_loss: 2.6699 - learning_rate: 5.0000e-06\n",
            "Epoch 324/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.8949 - loss: 0.4666 - val_accuracy: 0.1833 - val_loss: 2.6613 - learning_rate: 5.0000e-06\n",
            "Epoch 325/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8918 - loss: 0.4732 - val_accuracy: 0.1833 - val_loss: 2.6527 - learning_rate: 5.0000e-06\n",
            "Epoch 326/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9015 - loss: 0.4784 - val_accuracy: 0.1857 - val_loss: 2.6440 - learning_rate: 5.0000e-06\n",
            "Epoch 327/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8954 - loss: 0.4768 - val_accuracy: 0.1881 - val_loss: 2.6354 - learning_rate: 5.0000e-06\n",
            "Epoch 328/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8923 - loss: 0.4780 - val_accuracy: 0.1905 - val_loss: 2.6269 - learning_rate: 5.0000e-06\n",
            "Epoch 329/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8929 - loss: 0.4728 - val_accuracy: 0.1917 - val_loss: 2.6185 - learning_rate: 5.0000e-06\n",
            "Epoch 330/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.8995 - loss: 0.4686 - val_accuracy: 0.1940 - val_loss: 2.6099 - learning_rate: 5.0000e-06\n",
            "Epoch 331/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - accuracy: 0.8969 - loss: 0.4792 - val_accuracy: 0.1964 - val_loss: 2.6011 - learning_rate: 5.0000e-06\n",
            "Epoch 332/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.8985 - loss: 0.4807 - val_accuracy: 0.1988 - val_loss: 2.5923 - learning_rate: 5.0000e-06\n",
            "Epoch 333/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8980 - loss: 0.4643 - val_accuracy: 0.2012 - val_loss: 2.5837 - learning_rate: 5.0000e-06\n",
            "Epoch 334/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9000 - loss: 0.4755 - val_accuracy: 0.2024 - val_loss: 2.5746 - learning_rate: 5.0000e-06\n",
            "Epoch 335/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9015 - loss: 0.4638 - val_accuracy: 0.2048 - val_loss: 2.5657 - learning_rate: 5.0000e-06\n",
            "Epoch 336/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8954 - loss: 0.4628 - val_accuracy: 0.2060 - val_loss: 2.5569 - learning_rate: 5.0000e-06\n",
            "Epoch 337/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9000 - loss: 0.4729 - val_accuracy: 0.2060 - val_loss: 2.5482 - learning_rate: 5.0000e-06\n",
            "Epoch 338/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9087 - loss: 0.4605 - val_accuracy: 0.2083 - val_loss: 2.5391 - learning_rate: 5.0000e-06\n",
            "Epoch 339/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8990 - loss: 0.4619 - val_accuracy: 0.2107 - val_loss: 2.5297 - learning_rate: 5.0000e-06\n",
            "Epoch 340/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9041 - loss: 0.4776 - val_accuracy: 0.2119 - val_loss: 2.5206 - learning_rate: 5.0000e-06\n",
            "Epoch 341/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9056 - loss: 0.4546 - val_accuracy: 0.2167 - val_loss: 2.5115 - learning_rate: 5.0000e-06\n",
            "Epoch 342/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8934 - loss: 0.4726 - val_accuracy: 0.2179 - val_loss: 2.5023 - learning_rate: 5.0000e-06\n",
            "Epoch 343/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9036 - loss: 0.4494 - val_accuracy: 0.2202 - val_loss: 2.4929 - learning_rate: 5.0000e-06\n",
            "Epoch 344/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8944 - loss: 0.4736 - val_accuracy: 0.2286 - val_loss: 2.4838 - learning_rate: 5.0000e-06\n",
            "Epoch 345/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8964 - loss: 0.4750 - val_accuracy: 0.2345 - val_loss: 2.4745 - learning_rate: 5.0000e-06\n",
            "Epoch 346/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8969 - loss: 0.4670 - val_accuracy: 0.2369 - val_loss: 2.4649 - learning_rate: 5.0000e-06\n",
            "Epoch 347/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8954 - loss: 0.4889 - val_accuracy: 0.2381 - val_loss: 2.4552 - learning_rate: 5.0000e-06\n",
            "Epoch 348/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9005 - loss: 0.4637 - val_accuracy: 0.2405 - val_loss: 2.4455 - learning_rate: 5.0000e-06\n",
            "Epoch 349/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8944 - loss: 0.4723 - val_accuracy: 0.2429 - val_loss: 2.4358 - learning_rate: 5.0000e-06\n",
            "Epoch 350/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9000 - loss: 0.4619 - val_accuracy: 0.2440 - val_loss: 2.4259 - learning_rate: 5.0000e-06\n",
            "Epoch 351/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8995 - loss: 0.4698 - val_accuracy: 0.2452 - val_loss: 2.4162 - learning_rate: 5.0000e-06\n",
            "Epoch 352/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8969 - loss: 0.4717 - val_accuracy: 0.2488 - val_loss: 2.4064 - learning_rate: 5.0000e-06\n",
            "Epoch 353/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.8954 - loss: 0.4734 - val_accuracy: 0.2512 - val_loss: 2.3964 - learning_rate: 5.0000e-06\n",
            "Epoch 354/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9077 - loss: 0.4573 - val_accuracy: 0.2524 - val_loss: 2.3864 - learning_rate: 5.0000e-06\n",
            "Epoch 355/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9000 - loss: 0.4598 - val_accuracy: 0.2548 - val_loss: 2.3765 - learning_rate: 5.0000e-06\n",
            "Epoch 356/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9051 - loss: 0.4736 - val_accuracy: 0.2548 - val_loss: 2.3662 - learning_rate: 5.0000e-06\n",
            "Epoch 357/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9056 - loss: 0.4660 - val_accuracy: 0.2560 - val_loss: 2.3560 - learning_rate: 5.0000e-06\n",
            "Epoch 358/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9092 - loss: 0.4493 - val_accuracy: 0.2607 - val_loss: 2.3458 - learning_rate: 5.0000e-06\n",
            "Epoch 359/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9082 - loss: 0.4522 - val_accuracy: 0.2607 - val_loss: 2.3357 - learning_rate: 5.0000e-06\n",
            "Epoch 360/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8990 - loss: 0.4731 - val_accuracy: 0.2619 - val_loss: 2.3256 - learning_rate: 5.0000e-06\n",
            "Epoch 361/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9056 - loss: 0.4633 - val_accuracy: 0.2690 - val_loss: 2.3156 - learning_rate: 5.0000e-06\n",
            "Epoch 362/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8969 - loss: 0.4746 - val_accuracy: 0.2690 - val_loss: 2.3054 - learning_rate: 5.0000e-06\n",
            "Epoch 363/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9056 - loss: 0.4520 - val_accuracy: 0.2726 - val_loss: 2.2951 - learning_rate: 5.0000e-06\n",
            "Epoch 364/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9046 - loss: 0.4732 - val_accuracy: 0.2774 - val_loss: 2.2845 - learning_rate: 5.0000e-06\n",
            "Epoch 365/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9143 - loss: 0.4561 - val_accuracy: 0.2786 - val_loss: 2.2743 - learning_rate: 5.0000e-06\n",
            "Epoch 366/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9031 - loss: 0.4564 - val_accuracy: 0.2810 - val_loss: 2.2637 - learning_rate: 5.0000e-06\n",
            "Epoch 367/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8944 - loss: 0.4665 - val_accuracy: 0.2810 - val_loss: 2.2534 - learning_rate: 5.0000e-06\n",
            "Epoch 368/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8980 - loss: 0.4836 - val_accuracy: 0.2869 - val_loss: 2.2427 - learning_rate: 5.0000e-06\n",
            "Epoch 369/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9102 - loss: 0.4777 - val_accuracy: 0.2893 - val_loss: 2.2321 - learning_rate: 5.0000e-06\n",
            "Epoch 370/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9010 - loss: 0.4700 - val_accuracy: 0.2929 - val_loss: 2.2213 - learning_rate: 5.0000e-06\n",
            "Epoch 371/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8985 - loss: 0.4754 - val_accuracy: 0.2976 - val_loss: 2.2105 - learning_rate: 5.0000e-06\n",
            "Epoch 372/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9133 - loss: 0.4577 - val_accuracy: 0.2988 - val_loss: 2.1998 - learning_rate: 5.0000e-06\n",
            "Epoch 373/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8954 - loss: 0.4727 - val_accuracy: 0.3024 - val_loss: 2.1891 - learning_rate: 5.0000e-06\n",
            "Epoch 374/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9046 - loss: 0.4473 - val_accuracy: 0.3060 - val_loss: 2.1783 - learning_rate: 5.0000e-06\n",
            "Epoch 375/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8923 - loss: 0.4834 - val_accuracy: 0.3083 - val_loss: 2.1677 - learning_rate: 5.0000e-06\n",
            "Epoch 376/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9010 - loss: 0.4517 - val_accuracy: 0.3131 - val_loss: 2.1573 - learning_rate: 5.0000e-06\n",
            "Epoch 377/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.8949 - loss: 0.4707 - val_accuracy: 0.3167 - val_loss: 2.1467 - learning_rate: 5.0000e-06\n",
            "Epoch 378/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9092 - loss: 0.4626 - val_accuracy: 0.3190 - val_loss: 2.1360 - learning_rate: 5.0000e-06\n",
            "Epoch 379/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8990 - loss: 0.4888 - val_accuracy: 0.3238 - val_loss: 2.1255 - learning_rate: 5.0000e-06\n",
            "Epoch 380/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9036 - loss: 0.4494 - val_accuracy: 0.3238 - val_loss: 2.1148 - learning_rate: 5.0000e-06\n",
            "Epoch 381/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9031 - loss: 0.4518 - val_accuracy: 0.3298 - val_loss: 2.1043 - learning_rate: 5.0000e-06\n",
            "Epoch 382/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8949 - loss: 0.4735 - val_accuracy: 0.3357 - val_loss: 2.0937 - learning_rate: 5.0000e-06\n",
            "Epoch 383/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9077 - loss: 0.4571 - val_accuracy: 0.3369 - val_loss: 2.0831 - learning_rate: 5.0000e-06\n",
            "Epoch 384/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8980 - loss: 0.4725 - val_accuracy: 0.3393 - val_loss: 2.0724 - learning_rate: 5.0000e-06\n",
            "Epoch 385/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8959 - loss: 0.4733 - val_accuracy: 0.3464 - val_loss: 2.0618 - learning_rate: 5.0000e-06\n",
            "Epoch 386/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9061 - loss: 0.4635 - val_accuracy: 0.3488 - val_loss: 2.0512 - learning_rate: 5.0000e-06\n",
            "Epoch 387/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9000 - loss: 0.4569 - val_accuracy: 0.3488 - val_loss: 2.0408 - learning_rate: 5.0000e-06\n",
            "Epoch 388/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9015 - loss: 0.4500 - val_accuracy: 0.3512 - val_loss: 2.0300 - learning_rate: 5.0000e-06\n",
            "Epoch 389/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9000 - loss: 0.4664 - val_accuracy: 0.3536 - val_loss: 2.0195 - learning_rate: 5.0000e-06\n",
            "Epoch 390/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8985 - loss: 0.4591 - val_accuracy: 0.3571 - val_loss: 2.0088 - learning_rate: 5.0000e-06\n",
            "Epoch 391/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9061 - loss: 0.4533 - val_accuracy: 0.3607 - val_loss: 1.9982 - learning_rate: 5.0000e-06\n",
            "Epoch 392/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9051 - loss: 0.4485 - val_accuracy: 0.3607 - val_loss: 1.9875 - learning_rate: 5.0000e-06\n",
            "Epoch 393/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9010 - loss: 0.4433 - val_accuracy: 0.3667 - val_loss: 1.9769 - learning_rate: 5.0000e-06\n",
            "Epoch 394/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9015 - loss: 0.4658 - val_accuracy: 0.3679 - val_loss: 1.9661 - learning_rate: 5.0000e-06\n",
            "Epoch 395/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9158 - loss: 0.4331 - val_accuracy: 0.3690 - val_loss: 1.9551 - learning_rate: 5.0000e-06\n",
            "Epoch 396/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9015 - loss: 0.4738 - val_accuracy: 0.3738 - val_loss: 1.9443 - learning_rate: 5.0000e-06\n",
            "Epoch 397/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9005 - loss: 0.4588 - val_accuracy: 0.3762 - val_loss: 1.9338 - learning_rate: 5.0000e-06\n",
            "Epoch 398/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8929 - loss: 0.4763 - val_accuracy: 0.3774 - val_loss: 1.9232 - learning_rate: 5.0000e-06\n",
            "Epoch 399/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9005 - loss: 0.4660 - val_accuracy: 0.3798 - val_loss: 1.9124 - learning_rate: 5.0000e-06\n",
            "Epoch 400/400\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9056 - loss: 0.4615 - val_accuracy: 0.3833 - val_loss: 1.9018 - learning_rate: 5.0000e-06\n",
            "Epoch 1/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24s/step - accuracy: 0.8959 - loss: 0.4706 - val_accuracy: 0.3845 - val_loss: 1.8948 - learning_rate: 1.0000e-04\n",
            "Epoch 2/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9066 - loss: 0.4513 - val_accuracy: 0.3893 - val_loss: 1.8882 - learning_rate: 1.0000e-04\n",
            "Epoch 3/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9122 - loss: 0.4356 - val_accuracy: 0.3952 - val_loss: 1.8701 - learning_rate: 1.0000e-04\n",
            "Epoch 4/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9056 - loss: 0.4494 - val_accuracy: 0.4048 - val_loss: 1.8534 - learning_rate: 1.0000e-04\n",
            "Epoch 5/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.9056 - loss: 0.4431 - val_accuracy: 0.4143 - val_loss: 1.8358 - learning_rate: 1.0000e-04\n",
            "Epoch 6/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.9138 - loss: 0.4295 - val_accuracy: 0.4179 - val_loss: 1.8260 - learning_rate: 1.0000e-04\n",
            "Epoch 7/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9092 - loss: 0.4419 - val_accuracy: 0.4214 - val_loss: 1.8126 - learning_rate: 1.0000e-04\n",
            "Epoch 8/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9148 - loss: 0.4163 - val_accuracy: 0.4286 - val_loss: 1.7956 - learning_rate: 1.0000e-04\n",
            "Epoch 9/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9179 - loss: 0.4101 - val_accuracy: 0.4357 - val_loss: 1.7822 - learning_rate: 1.0000e-04\n",
            "Epoch 10/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9209 - loss: 0.4033 - val_accuracy: 0.4464 - val_loss: 1.7648 - learning_rate: 1.0000e-04\n",
            "Epoch 11/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9179 - loss: 0.4062 - val_accuracy: 0.4560 - val_loss: 1.7392 - learning_rate: 1.0000e-04\n",
            "Epoch 12/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9214 - loss: 0.4072 - val_accuracy: 0.4667 - val_loss: 1.7158 - learning_rate: 1.0000e-04\n",
            "Epoch 13/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9342 - loss: 0.3679 - val_accuracy: 0.4750 - val_loss: 1.6942 - learning_rate: 1.0000e-04\n",
            "Epoch 14/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9301 - loss: 0.3803 - val_accuracy: 0.4857 - val_loss: 1.6724 - learning_rate: 1.0000e-04\n",
            "Epoch 15/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9260 - loss: 0.3691 - val_accuracy: 0.4869 - val_loss: 1.6514 - learning_rate: 1.0000e-04\n",
            "Epoch 16/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9265 - loss: 0.3821 - val_accuracy: 0.4929 - val_loss: 1.6299 - learning_rate: 1.0000e-04\n",
            "Epoch 17/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9337 - loss: 0.3596 - val_accuracy: 0.4976 - val_loss: 1.6133 - learning_rate: 1.0000e-04\n",
            "Epoch 18/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9337 - loss: 0.3571 - val_accuracy: 0.5000 - val_loss: 1.5987 - learning_rate: 1.0000e-04\n",
            "Epoch 19/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9306 - loss: 0.3551 - val_accuracy: 0.5060 - val_loss: 1.5834 - learning_rate: 1.0000e-04\n",
            "Epoch 20/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9347 - loss: 0.3633 - val_accuracy: 0.5119 - val_loss: 1.5683 - learning_rate: 1.0000e-04\n",
            "Epoch 21/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9352 - loss: 0.3539 - val_accuracy: 0.5155 - val_loss: 1.5529 - learning_rate: 1.0000e-04\n",
            "Epoch 22/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9352 - loss: 0.3490 - val_accuracy: 0.5226 - val_loss: 1.5354 - learning_rate: 1.0000e-04\n",
            "Epoch 23/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9321 - loss: 0.3512 - val_accuracy: 0.5286 - val_loss: 1.5185 - learning_rate: 1.0000e-04\n",
            "Epoch 24/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9378 - loss: 0.3492 - val_accuracy: 0.5310 - val_loss: 1.5020 - learning_rate: 1.0000e-04\n",
            "Epoch 25/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9434 - loss: 0.3344 - val_accuracy: 0.5369 - val_loss: 1.4887 - learning_rate: 1.0000e-04\n",
            "Epoch 26/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9429 - loss: 0.3435 - val_accuracy: 0.5405 - val_loss: 1.4752 - learning_rate: 1.0000e-04\n",
            "Epoch 27/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9408 - loss: 0.3238 - val_accuracy: 0.5488 - val_loss: 1.4638 - learning_rate: 1.0000e-04\n",
            "Epoch 28/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9449 - loss: 0.3175 - val_accuracy: 0.5524 - val_loss: 1.4530 - learning_rate: 1.0000e-04\n",
            "Epoch 29/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9357 - loss: 0.3345 - val_accuracy: 0.5548 - val_loss: 1.4409 - learning_rate: 1.0000e-04\n",
            "Epoch 30/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9413 - loss: 0.3269 - val_accuracy: 0.5583 - val_loss: 1.4275 - learning_rate: 1.0000e-04\n",
            "Epoch 31/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9388 - loss: 0.3144 - val_accuracy: 0.5643 - val_loss: 1.4121 - learning_rate: 1.0000e-04\n",
            "Epoch 32/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9490 - loss: 0.3078 - val_accuracy: 0.5726 - val_loss: 1.3973 - learning_rate: 1.0000e-04\n",
            "Epoch 33/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9444 - loss: 0.3116 - val_accuracy: 0.5738 - val_loss: 1.3847 - learning_rate: 1.0000e-04\n",
            "Epoch 34/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9536 - loss: 0.2977 - val_accuracy: 0.5786 - val_loss: 1.3727 - learning_rate: 1.0000e-04\n",
            "Epoch 35/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9388 - loss: 0.3137 - val_accuracy: 0.5857 - val_loss: 1.3591 - learning_rate: 1.0000e-04\n",
            "Epoch 36/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9490 - loss: 0.3008 - val_accuracy: 0.5940 - val_loss: 1.3441 - learning_rate: 1.0000e-04\n",
            "Epoch 37/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9510 - loss: 0.2943 - val_accuracy: 0.5964 - val_loss: 1.3290 - learning_rate: 1.0000e-04\n",
            "Epoch 38/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9541 - loss: 0.2816 - val_accuracy: 0.5976 - val_loss: 1.3143 - learning_rate: 1.0000e-04\n",
            "Epoch 39/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.9495 - loss: 0.2891 - val_accuracy: 0.5988 - val_loss: 1.2974 - learning_rate: 1.0000e-04\n",
            "Epoch 40/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9536 - loss: 0.2786 - val_accuracy: 0.6036 - val_loss: 1.2811 - learning_rate: 1.0000e-04\n",
            "Epoch 41/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9474 - loss: 0.2945 - val_accuracy: 0.6095 - val_loss: 1.2668 - learning_rate: 1.0000e-04\n",
            "Epoch 42/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9520 - loss: 0.2844 - val_accuracy: 0.6190 - val_loss: 1.2486 - learning_rate: 1.0000e-04\n",
            "Epoch 43/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9485 - loss: 0.2742 - val_accuracy: 0.6262 - val_loss: 1.2304 - learning_rate: 1.0000e-04\n",
            "Epoch 44/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9556 - loss: 0.2746 - val_accuracy: 0.6333 - val_loss: 1.2135 - learning_rate: 1.0000e-04\n",
            "Epoch 45/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9551 - loss: 0.2666 - val_accuracy: 0.6429 - val_loss: 1.1972 - learning_rate: 1.0000e-04\n",
            "Epoch 46/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9536 - loss: 0.2629 - val_accuracy: 0.6452 - val_loss: 1.1792 - learning_rate: 1.0000e-04\n",
            "Epoch 47/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9566 - loss: 0.2757 - val_accuracy: 0.6512 - val_loss: 1.1635 - learning_rate: 1.0000e-04\n",
            "Epoch 48/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9622 - loss: 0.2547 - val_accuracy: 0.6607 - val_loss: 1.1504 - learning_rate: 1.0000e-04\n",
            "Epoch 49/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9526 - loss: 0.2814 - val_accuracy: 0.6643 - val_loss: 1.1356 - learning_rate: 1.0000e-04\n",
            "Epoch 50/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9551 - loss: 0.2550 - val_accuracy: 0.6679 - val_loss: 1.1218 - learning_rate: 1.0000e-04\n",
            "Epoch 51/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9633 - loss: 0.2519 - val_accuracy: 0.6702 - val_loss: 1.1114 - learning_rate: 1.0000e-04\n",
            "Epoch 52/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9587 - loss: 0.2572 - val_accuracy: 0.6726 - val_loss: 1.1004 - learning_rate: 1.0000e-04\n",
            "Epoch 53/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - accuracy: 0.9597 - loss: 0.2527 - val_accuracy: 0.6774 - val_loss: 1.0921 - learning_rate: 1.0000e-04\n",
            "Epoch 54/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9617 - loss: 0.2529 - val_accuracy: 0.6821 - val_loss: 1.0816 - learning_rate: 1.0000e-04\n",
            "Epoch 55/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9638 - loss: 0.2476 - val_accuracy: 0.6857 - val_loss: 1.0709 - learning_rate: 1.0000e-04\n",
            "Epoch 56/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9694 - loss: 0.2400 - val_accuracy: 0.6869 - val_loss: 1.0581 - learning_rate: 1.0000e-04\n",
            "Epoch 57/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9648 - loss: 0.2348 - val_accuracy: 0.6929 - val_loss: 1.0441 - learning_rate: 1.0000e-04\n",
            "Epoch 58/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9607 - loss: 0.2438 - val_accuracy: 0.6964 - val_loss: 1.0301 - learning_rate: 1.0000e-04\n",
            "Epoch 59/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9582 - loss: 0.2394 - val_accuracy: 0.6988 - val_loss: 1.0173 - learning_rate: 1.0000e-04\n",
            "Epoch 60/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9638 - loss: 0.2370 - val_accuracy: 0.7000 - val_loss: 1.0031 - learning_rate: 1.0000e-04\n",
            "Epoch 61/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9663 - loss: 0.2280 - val_accuracy: 0.7060 - val_loss: 0.9870 - learning_rate: 1.0000e-04\n",
            "Epoch 62/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9724 - loss: 0.2168 - val_accuracy: 0.7107 - val_loss: 0.9732 - learning_rate: 1.0000e-04\n",
            "Epoch 63/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9668 - loss: 0.2253 - val_accuracy: 0.7143 - val_loss: 0.9628 - learning_rate: 1.0000e-04\n",
            "Epoch 64/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9638 - loss: 0.2225 - val_accuracy: 0.7155 - val_loss: 0.9546 - learning_rate: 1.0000e-04\n",
            "Epoch 65/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9673 - loss: 0.2209 - val_accuracy: 0.7167 - val_loss: 0.9454 - learning_rate: 1.0000e-04\n",
            "Epoch 66/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9719 - loss: 0.2117 - val_accuracy: 0.7167 - val_loss: 0.9373 - learning_rate: 1.0000e-04\n",
            "Epoch 67/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9673 - loss: 0.2160 - val_accuracy: 0.7167 - val_loss: 0.9285 - learning_rate: 1.0000e-04\n",
            "Epoch 68/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.9714 - loss: 0.2156 - val_accuracy: 0.7190 - val_loss: 0.9178 - learning_rate: 1.0000e-04\n",
            "Epoch 69/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9679 - loss: 0.2180 - val_accuracy: 0.7238 - val_loss: 0.9062 - learning_rate: 1.0000e-04\n",
            "Epoch 70/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9745 - loss: 0.2023 - val_accuracy: 0.7262 - val_loss: 0.8950 - learning_rate: 1.0000e-04\n",
            "Epoch 71/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9704 - loss: 0.2081 - val_accuracy: 0.7298 - val_loss: 0.8858 - learning_rate: 1.0000e-04\n",
            "Epoch 72/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9709 - loss: 0.2061 - val_accuracy: 0.7345 - val_loss: 0.8756 - learning_rate: 1.0000e-04\n",
            "Epoch 73/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9617 - loss: 0.2243 - val_accuracy: 0.7440 - val_loss: 0.8650 - learning_rate: 1.0000e-04\n",
            "Epoch 74/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9699 - loss: 0.1982 - val_accuracy: 0.7452 - val_loss: 0.8547 - learning_rate: 1.0000e-04\n",
            "Epoch 75/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9673 - loss: 0.2081 - val_accuracy: 0.7512 - val_loss: 0.8410 - learning_rate: 1.0000e-04\n",
            "Epoch 76/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9724 - loss: 0.2016 - val_accuracy: 0.7536 - val_loss: 0.8256 - learning_rate: 1.0000e-04\n",
            "Epoch 77/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9719 - loss: 0.1996 - val_accuracy: 0.7583 - val_loss: 0.8123 - learning_rate: 1.0000e-04\n",
            "Epoch 78/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9735 - loss: 0.2003 - val_accuracy: 0.7631 - val_loss: 0.8003 - learning_rate: 1.0000e-04\n",
            "Epoch 79/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9750 - loss: 0.1880 - val_accuracy: 0.7643 - val_loss: 0.7893 - learning_rate: 1.0000e-04\n",
            "Epoch 80/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9755 - loss: 0.1901 - val_accuracy: 0.7679 - val_loss: 0.7807 - learning_rate: 1.0000e-04\n",
            "Epoch 81/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9724 - loss: 0.1860 - val_accuracy: 0.7714 - val_loss: 0.7715 - learning_rate: 1.0000e-04\n",
            "Epoch 82/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9679 - loss: 0.2070 - val_accuracy: 0.7726 - val_loss: 0.7609 - learning_rate: 1.0000e-04\n",
            "Epoch 83/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9730 - loss: 0.1930 - val_accuracy: 0.7714 - val_loss: 0.7493 - learning_rate: 1.0000e-04\n",
            "Epoch 84/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9699 - loss: 0.1903 - val_accuracy: 0.7738 - val_loss: 0.7421 - learning_rate: 1.0000e-04\n",
            "Epoch 85/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9704 - loss: 0.1906 - val_accuracy: 0.7726 - val_loss: 0.7375 - learning_rate: 1.0000e-04\n",
            "Epoch 86/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9765 - loss: 0.1916 - val_accuracy: 0.7762 - val_loss: 0.7354 - learning_rate: 1.0000e-04\n",
            "Epoch 87/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9735 - loss: 0.1840 - val_accuracy: 0.7774 - val_loss: 0.7305 - learning_rate: 5.0000e-05\n",
            "Epoch 88/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9760 - loss: 0.1836 - val_accuracy: 0.7774 - val_loss: 0.7258 - learning_rate: 5.0000e-05\n",
            "Epoch 89/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9724 - loss: 0.1875 - val_accuracy: 0.7786 - val_loss: 0.7210 - learning_rate: 5.0000e-05\n",
            "Epoch 90/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9755 - loss: 0.1782 - val_accuracy: 0.7810 - val_loss: 0.7166 - learning_rate: 5.0000e-05\n",
            "Epoch 91/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9719 - loss: 0.1932 - val_accuracy: 0.7845 - val_loss: 0.7128 - learning_rate: 5.0000e-05\n",
            "Epoch 92/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9755 - loss: 0.1716 - val_accuracy: 0.7893 - val_loss: 0.7074 - learning_rate: 5.0000e-05\n",
            "Epoch 93/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9719 - loss: 0.1845 - val_accuracy: 0.7905 - val_loss: 0.7015 - learning_rate: 5.0000e-05\n",
            "Epoch 94/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9796 - loss: 0.1677 - val_accuracy: 0.7929 - val_loss: 0.6953 - learning_rate: 5.0000e-05\n",
            "Epoch 95/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9735 - loss: 0.1737 - val_accuracy: 0.7952 - val_loss: 0.6891 - learning_rate: 5.0000e-05\n",
            "Epoch 96/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9760 - loss: 0.1789 - val_accuracy: 0.7964 - val_loss: 0.6809 - learning_rate: 5.0000e-05\n",
            "Epoch 97/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9750 - loss: 0.1725 - val_accuracy: 0.8012 - val_loss: 0.6726 - learning_rate: 5.0000e-05\n",
            "Epoch 98/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9796 - loss: 0.1800 - val_accuracy: 0.8000 - val_loss: 0.6639 - learning_rate: 5.0000e-05\n",
            "Epoch 99/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9724 - loss: 0.1775 - val_accuracy: 0.8012 - val_loss: 0.6562 - learning_rate: 5.0000e-05\n",
            "Epoch 100/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9811 - loss: 0.1701 - val_accuracy: 0.8036 - val_loss: 0.6504 - learning_rate: 2.5000e-05\n",
            "Epoch 101/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9760 - loss: 0.1719 - val_accuracy: 0.8036 - val_loss: 0.6444 - learning_rate: 2.5000e-05\n",
            "Epoch 102/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9755 - loss: 0.1814 - val_accuracy: 0.8036 - val_loss: 0.6383 - learning_rate: 2.5000e-05\n",
            "Epoch 103/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9765 - loss: 0.1778 - val_accuracy: 0.8060 - val_loss: 0.6322 - learning_rate: 2.5000e-05\n",
            "Epoch 104/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9755 - loss: 0.1738 - val_accuracy: 0.8107 - val_loss: 0.6260 - learning_rate: 2.5000e-05\n",
            "Epoch 105/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9791 - loss: 0.1751 - val_accuracy: 0.8131 - val_loss: 0.6202 - learning_rate: 2.5000e-05\n",
            "Epoch 106/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9730 - loss: 0.1816 - val_accuracy: 0.8143 - val_loss: 0.6144 - learning_rate: 2.5000e-05\n",
            "Epoch 107/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9791 - loss: 0.1694 - val_accuracy: 0.8167 - val_loss: 0.6088 - learning_rate: 2.5000e-05\n",
            "Epoch 108/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9776 - loss: 0.1706 - val_accuracy: 0.8179 - val_loss: 0.6031 - learning_rate: 2.5000e-05\n",
            "Epoch 109/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9776 - loss: 0.1662 - val_accuracy: 0.8214 - val_loss: 0.5979 - learning_rate: 1.2500e-05\n",
            "Epoch 110/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1669 - val_accuracy: 0.8250 - val_loss: 0.5928 - learning_rate: 1.2500e-05\n",
            "Epoch 111/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9719 - loss: 0.1738 - val_accuracy: 0.8262 - val_loss: 0.5881 - learning_rate: 1.2500e-05\n",
            "Epoch 112/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9755 - loss: 0.1763 - val_accuracy: 0.8274 - val_loss: 0.5835 - learning_rate: 1.2500e-05\n",
            "Epoch 113/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9735 - loss: 0.1800 - val_accuracy: 0.8298 - val_loss: 0.5790 - learning_rate: 1.2500e-05\n",
            "Epoch 114/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9770 - loss: 0.1702 - val_accuracy: 0.8310 - val_loss: 0.5742 - learning_rate: 1.2500e-05\n",
            "Epoch 115/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9724 - loss: 0.1776 - val_accuracy: 0.8321 - val_loss: 0.5697 - learning_rate: 1.2500e-05\n",
            "Epoch 116/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9735 - loss: 0.1771 - val_accuracy: 0.8345 - val_loss: 0.5649 - learning_rate: 1.2500e-05\n",
            "Epoch 117/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9796 - loss: 0.1681 - val_accuracy: 0.8381 - val_loss: 0.5604 - learning_rate: 1.2500e-05\n",
            "Epoch 118/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9801 - loss: 0.1680 - val_accuracy: 0.8393 - val_loss: 0.5559 - learning_rate: 6.2500e-06\n",
            "Epoch 119/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9740 - loss: 0.1753 - val_accuracy: 0.8417 - val_loss: 0.5513 - learning_rate: 6.2500e-06\n",
            "Epoch 120/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1705 - val_accuracy: 0.8417 - val_loss: 0.5469 - learning_rate: 6.2500e-06\n",
            "Epoch 121/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9709 - loss: 0.1818 - val_accuracy: 0.8452 - val_loss: 0.5424 - learning_rate: 6.2500e-06\n",
            "Epoch 122/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9837 - loss: 0.1634 - val_accuracy: 0.8476 - val_loss: 0.5380 - learning_rate: 6.2500e-06\n",
            "Epoch 123/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9755 - loss: 0.1810 - val_accuracy: 0.8500 - val_loss: 0.5336 - learning_rate: 6.2500e-06\n",
            "Epoch 124/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - accuracy: 0.9760 - loss: 0.1795 - val_accuracy: 0.8512 - val_loss: 0.5292 - learning_rate: 6.2500e-06\n",
            "Epoch 125/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9755 - loss: 0.1770 - val_accuracy: 0.8524 - val_loss: 0.5250 - learning_rate: 6.2500e-06\n",
            "Epoch 126/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9719 - loss: 0.1781 - val_accuracy: 0.8524 - val_loss: 0.5210 - learning_rate: 6.2500e-06\n",
            "Epoch 127/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9781 - loss: 0.1688 - val_accuracy: 0.8536 - val_loss: 0.5169 - learning_rate: 6.2500e-06\n",
            "Epoch 128/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9704 - loss: 0.1781 - val_accuracy: 0.8560 - val_loss: 0.5129 - learning_rate: 5.0000e-06\n",
            "Epoch 129/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9755 - loss: 0.1632 - val_accuracy: 0.8595 - val_loss: 0.5089 - learning_rate: 5.0000e-06\n",
            "Epoch 130/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9735 - loss: 0.1740 - val_accuracy: 0.8631 - val_loss: 0.5050 - learning_rate: 5.0000e-06\n",
            "Epoch 131/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9735 - loss: 0.1712 - val_accuracy: 0.8631 - val_loss: 0.5011 - learning_rate: 5.0000e-06\n",
            "Epoch 132/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9740 - loss: 0.1776 - val_accuracy: 0.8631 - val_loss: 0.4973 - learning_rate: 5.0000e-06\n",
            "Epoch 133/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9811 - loss: 0.1646 - val_accuracy: 0.8631 - val_loss: 0.4935 - learning_rate: 5.0000e-06\n",
            "Epoch 134/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.9750 - loss: 0.1800 - val_accuracy: 0.8631 - val_loss: 0.4899 - learning_rate: 5.0000e-06\n",
            "Epoch 135/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9745 - loss: 0.1692 - val_accuracy: 0.8631 - val_loss: 0.4863 - learning_rate: 5.0000e-06\n",
            "Epoch 136/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9791 - loss: 0.1709 - val_accuracy: 0.8643 - val_loss: 0.4828 - learning_rate: 5.0000e-06\n",
            "Epoch 137/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9745 - loss: 0.1733 - val_accuracy: 0.8667 - val_loss: 0.4792 - learning_rate: 5.0000e-06\n",
            "Epoch 138/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9776 - loss: 0.1604 - val_accuracy: 0.8690 - val_loss: 0.4757 - learning_rate: 5.0000e-06\n",
            "Epoch 139/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9755 - loss: 0.1741 - val_accuracy: 0.8690 - val_loss: 0.4724 - learning_rate: 5.0000e-06\n",
            "Epoch 140/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9791 - loss: 0.1572 - val_accuracy: 0.8690 - val_loss: 0.4691 - learning_rate: 5.0000e-06\n",
            "Epoch 141/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9724 - loss: 0.1753 - val_accuracy: 0.8702 - val_loss: 0.4659 - learning_rate: 5.0000e-06\n",
            "Epoch 142/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9776 - loss: 0.1631 - val_accuracy: 0.8702 - val_loss: 0.4626 - learning_rate: 5.0000e-06\n",
            "Epoch 143/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9796 - loss: 0.1725 - val_accuracy: 0.8702 - val_loss: 0.4594 - learning_rate: 5.0000e-06\n",
            "Epoch 144/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9724 - loss: 0.1679 - val_accuracy: 0.8714 - val_loss: 0.4563 - learning_rate: 5.0000e-06\n",
            "Epoch 145/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9724 - loss: 0.1889 - val_accuracy: 0.8726 - val_loss: 0.4531 - learning_rate: 5.0000e-06\n",
            "Epoch 146/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9827 - loss: 0.1576 - val_accuracy: 0.8726 - val_loss: 0.4500 - learning_rate: 5.0000e-06\n",
            "Epoch 147/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9750 - loss: 0.1728 - val_accuracy: 0.8738 - val_loss: 0.4468 - learning_rate: 5.0000e-06\n",
            "Epoch 148/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9862 - loss: 0.1602 - val_accuracy: 0.8762 - val_loss: 0.4437 - learning_rate: 5.0000e-06\n",
            "Epoch 149/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9806 - loss: 0.1686 - val_accuracy: 0.8762 - val_loss: 0.4405 - learning_rate: 5.0000e-06\n",
            "Epoch 150/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9765 - loss: 0.1664 - val_accuracy: 0.8762 - val_loss: 0.4374 - learning_rate: 5.0000e-06\n",
            "Epoch 151/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9801 - loss: 0.1637 - val_accuracy: 0.8774 - val_loss: 0.4343 - learning_rate: 5.0000e-06\n",
            "Epoch 152/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9755 - loss: 0.1725 - val_accuracy: 0.8774 - val_loss: 0.4314 - learning_rate: 5.0000e-06\n",
            "Epoch 153/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9770 - loss: 0.1749 - val_accuracy: 0.8798 - val_loss: 0.4283 - learning_rate: 5.0000e-06\n",
            "Epoch 154/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9796 - loss: 0.1661 - val_accuracy: 0.8810 - val_loss: 0.4254 - learning_rate: 5.0000e-06\n",
            "Epoch 155/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1662 - val_accuracy: 0.8810 - val_loss: 0.4224 - learning_rate: 5.0000e-06\n",
            "Epoch 156/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9781 - loss: 0.1657 - val_accuracy: 0.8810 - val_loss: 0.4196 - learning_rate: 5.0000e-06\n",
            "Epoch 157/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9755 - loss: 0.1689 - val_accuracy: 0.8810 - val_loss: 0.4168 - learning_rate: 5.0000e-06\n",
            "Epoch 158/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9776 - loss: 0.1696 - val_accuracy: 0.8821 - val_loss: 0.4140 - learning_rate: 5.0000e-06\n",
            "Epoch 159/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9806 - loss: 0.1639 - val_accuracy: 0.8821 - val_loss: 0.4113 - learning_rate: 5.0000e-06\n",
            "Epoch 160/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9801 - loss: 0.1625 - val_accuracy: 0.8833 - val_loss: 0.4085 - learning_rate: 5.0000e-06\n",
            "Epoch 161/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9816 - loss: 0.1548 - val_accuracy: 0.8857 - val_loss: 0.4057 - learning_rate: 5.0000e-06\n",
            "Epoch 162/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9786 - loss: 0.1744 - val_accuracy: 0.8857 - val_loss: 0.4030 - learning_rate: 5.0000e-06\n",
            "Epoch 163/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9811 - loss: 0.1717 - val_accuracy: 0.8869 - val_loss: 0.4001 - learning_rate: 5.0000e-06\n",
            "Epoch 164/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9806 - loss: 0.1676 - val_accuracy: 0.8869 - val_loss: 0.3972 - learning_rate: 5.0000e-06\n",
            "Epoch 165/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9791 - loss: 0.1717 - val_accuracy: 0.8881 - val_loss: 0.3944 - learning_rate: 5.0000e-06\n",
            "Epoch 166/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9755 - loss: 0.1689 - val_accuracy: 0.8869 - val_loss: 0.3915 - learning_rate: 5.0000e-06\n",
            "Epoch 167/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9821 - loss: 0.1612 - val_accuracy: 0.8869 - val_loss: 0.3887 - learning_rate: 5.0000e-06\n",
            "Epoch 168/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9827 - loss: 0.1576 - val_accuracy: 0.8869 - val_loss: 0.3859 - learning_rate: 5.0000e-06\n",
            "Epoch 169/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1678 - val_accuracy: 0.8869 - val_loss: 0.3831 - learning_rate: 5.0000e-06\n",
            "Epoch 170/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9765 - loss: 0.1710 - val_accuracy: 0.8869 - val_loss: 0.3804 - learning_rate: 5.0000e-06\n",
            "Epoch 171/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9806 - loss: 0.1673 - val_accuracy: 0.8905 - val_loss: 0.3777 - learning_rate: 5.0000e-06\n",
            "Epoch 172/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9760 - loss: 0.1715 - val_accuracy: 0.8905 - val_loss: 0.3750 - learning_rate: 5.0000e-06\n",
            "Epoch 173/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9745 - loss: 0.1725 - val_accuracy: 0.8917 - val_loss: 0.3724 - learning_rate: 5.0000e-06\n",
            "Epoch 174/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9827 - loss: 0.1563 - val_accuracy: 0.8940 - val_loss: 0.3697 - learning_rate: 5.0000e-06\n",
            "Epoch 175/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9791 - loss: 0.1671 - val_accuracy: 0.8940 - val_loss: 0.3671 - learning_rate: 5.0000e-06\n",
            "Epoch 176/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.9770 - loss: 0.1758 - val_accuracy: 0.8952 - val_loss: 0.3646 - learning_rate: 5.0000e-06\n",
            "Epoch 177/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9760 - loss: 0.1672 - val_accuracy: 0.8952 - val_loss: 0.3621 - learning_rate: 5.0000e-06\n",
            "Epoch 178/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9735 - loss: 0.1678 - val_accuracy: 0.8964 - val_loss: 0.3598 - learning_rate: 5.0000e-06\n",
            "Epoch 179/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9760 - loss: 0.1746 - val_accuracy: 0.8964 - val_loss: 0.3574 - learning_rate: 5.0000e-06\n",
            "Epoch 180/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9735 - loss: 0.1730 - val_accuracy: 0.8964 - val_loss: 0.3549 - learning_rate: 5.0000e-06\n",
            "Epoch 181/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9770 - loss: 0.1678 - val_accuracy: 0.8964 - val_loss: 0.3524 - learning_rate: 5.0000e-06\n",
            "Epoch 182/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9724 - loss: 0.1725 - val_accuracy: 0.8988 - val_loss: 0.3499 - learning_rate: 5.0000e-06\n",
            "Epoch 183/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9770 - loss: 0.1702 - val_accuracy: 0.8988 - val_loss: 0.3475 - learning_rate: 5.0000e-06\n",
            "Epoch 184/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9781 - loss: 0.1634 - val_accuracy: 0.8988 - val_loss: 0.3451 - learning_rate: 5.0000e-06\n",
            "Epoch 185/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9770 - loss: 0.1600 - val_accuracy: 0.8988 - val_loss: 0.3426 - learning_rate: 5.0000e-06\n",
            "Epoch 186/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9750 - loss: 0.1688 - val_accuracy: 0.8988 - val_loss: 0.3402 - learning_rate: 5.0000e-06\n",
            "Epoch 187/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9740 - loss: 0.1684 - val_accuracy: 0.8988 - val_loss: 0.3378 - learning_rate: 5.0000e-06\n",
            "Epoch 188/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9770 - loss: 0.1696 - val_accuracy: 0.8988 - val_loss: 0.3355 - learning_rate: 5.0000e-06\n",
            "Epoch 189/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9679 - loss: 0.1803 - val_accuracy: 0.9012 - val_loss: 0.3332 - learning_rate: 5.0000e-06\n",
            "Epoch 190/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9816 - loss: 0.1559 - val_accuracy: 0.9024 - val_loss: 0.3311 - learning_rate: 5.0000e-06\n",
            "Epoch 191/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9781 - loss: 0.1670 - val_accuracy: 0.9036 - val_loss: 0.3289 - learning_rate: 5.0000e-06\n",
            "Epoch 192/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9847 - loss: 0.1584 - val_accuracy: 0.9048 - val_loss: 0.3267 - learning_rate: 5.0000e-06\n",
            "Epoch 193/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9791 - loss: 0.1663 - val_accuracy: 0.9048 - val_loss: 0.3246 - learning_rate: 5.0000e-06\n",
            "Epoch 194/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9760 - loss: 0.1663 - val_accuracy: 0.9048 - val_loss: 0.3225 - learning_rate: 5.0000e-06\n",
            "Epoch 195/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9760 - loss: 0.1720 - val_accuracy: 0.9048 - val_loss: 0.3205 - learning_rate: 5.0000e-06\n",
            "Epoch 196/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9786 - loss: 0.1669 - val_accuracy: 0.9048 - val_loss: 0.3185 - learning_rate: 5.0000e-06\n",
            "Epoch 197/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9755 - loss: 0.1709 - val_accuracy: 0.9060 - val_loss: 0.3165 - learning_rate: 5.0000e-06\n",
            "Epoch 198/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9801 - loss: 0.1706 - val_accuracy: 0.9060 - val_loss: 0.3146 - learning_rate: 5.0000e-06\n",
            "Epoch 199/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9837 - loss: 0.1584 - val_accuracy: 0.9071 - val_loss: 0.3127 - learning_rate: 5.0000e-06\n",
            "Epoch 200/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9770 - loss: 0.1629 - val_accuracy: 0.9083 - val_loss: 0.3109 - learning_rate: 5.0000e-06\n",
            "Epoch 201/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1624 - val_accuracy: 0.9083 - val_loss: 0.3092 - learning_rate: 5.0000e-06\n",
            "Epoch 202/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9765 - loss: 0.1767 - val_accuracy: 0.9083 - val_loss: 0.3075 - learning_rate: 5.0000e-06\n",
            "Epoch 203/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9755 - loss: 0.1750 - val_accuracy: 0.9083 - val_loss: 0.3058 - learning_rate: 5.0000e-06\n",
            "Epoch 204/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9791 - loss: 0.1643 - val_accuracy: 0.9095 - val_loss: 0.3041 - learning_rate: 5.0000e-06\n",
            "Epoch 205/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9816 - loss: 0.1578 - val_accuracy: 0.9107 - val_loss: 0.3024 - learning_rate: 5.0000e-06\n",
            "Epoch 206/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9806 - loss: 0.1628 - val_accuracy: 0.9107 - val_loss: 0.3006 - learning_rate: 5.0000e-06\n",
            "Epoch 207/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9776 - loss: 0.1654 - val_accuracy: 0.9119 - val_loss: 0.2988 - learning_rate: 5.0000e-06\n",
            "Epoch 208/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9765 - loss: 0.1710 - val_accuracy: 0.9119 - val_loss: 0.2970 - learning_rate: 5.0000e-06\n",
            "Epoch 209/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9781 - loss: 0.1606 - val_accuracy: 0.9119 - val_loss: 0.2953 - learning_rate: 5.0000e-06\n",
            "Epoch 210/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9801 - loss: 0.1660 - val_accuracy: 0.9131 - val_loss: 0.2936 - learning_rate: 5.0000e-06\n",
            "Epoch 211/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9827 - loss: 0.1665 - val_accuracy: 0.9131 - val_loss: 0.2920 - learning_rate: 5.0000e-06\n",
            "Epoch 212/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9765 - loss: 0.1777 - val_accuracy: 0.9143 - val_loss: 0.2904 - learning_rate: 5.0000e-06\n",
            "Epoch 213/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.9796 - loss: 0.1593 - val_accuracy: 0.9143 - val_loss: 0.2889 - learning_rate: 5.0000e-06\n",
            "Epoch 214/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9837 - loss: 0.1587 - val_accuracy: 0.9131 - val_loss: 0.2874 - learning_rate: 5.0000e-06\n",
            "Epoch 215/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9740 - loss: 0.1652 - val_accuracy: 0.9131 - val_loss: 0.2858 - learning_rate: 5.0000e-06\n",
            "Epoch 216/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9832 - loss: 0.1550 - val_accuracy: 0.9143 - val_loss: 0.2843 - learning_rate: 5.0000e-06\n",
            "Epoch 217/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9796 - loss: 0.1614 - val_accuracy: 0.9143 - val_loss: 0.2829 - learning_rate: 5.0000e-06\n",
            "Epoch 218/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9776 - loss: 0.1654 - val_accuracy: 0.9143 - val_loss: 0.2814 - learning_rate: 5.0000e-06\n",
            "Epoch 219/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9816 - loss: 0.1627 - val_accuracy: 0.9167 - val_loss: 0.2799 - learning_rate: 5.0000e-06\n",
            "Epoch 220/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1602 - val_accuracy: 0.9167 - val_loss: 0.2784 - learning_rate: 5.0000e-06\n",
            "Epoch 221/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9781 - loss: 0.1666 - val_accuracy: 0.9167 - val_loss: 0.2770 - learning_rate: 5.0000e-06\n",
            "Epoch 222/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9806 - loss: 0.1622 - val_accuracy: 0.9167 - val_loss: 0.2756 - learning_rate: 5.0000e-06\n",
            "Epoch 223/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9760 - loss: 0.1809 - val_accuracy: 0.9167 - val_loss: 0.2743 - learning_rate: 5.0000e-06\n",
            "Epoch 224/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9740 - loss: 0.1690 - val_accuracy: 0.9179 - val_loss: 0.2729 - learning_rate: 5.0000e-06\n",
            "Epoch 225/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9801 - loss: 0.1628 - val_accuracy: 0.9179 - val_loss: 0.2715 - learning_rate: 5.0000e-06\n",
            "Epoch 226/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9781 - loss: 0.1647 - val_accuracy: 0.9167 - val_loss: 0.2701 - learning_rate: 5.0000e-06\n",
            "Epoch 227/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9776 - loss: 0.1648 - val_accuracy: 0.9179 - val_loss: 0.2688 - learning_rate: 5.0000e-06\n",
            "Epoch 228/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9740 - loss: 0.1655 - val_accuracy: 0.9190 - val_loss: 0.2675 - learning_rate: 5.0000e-06\n",
            "Epoch 229/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9760 - loss: 0.1621 - val_accuracy: 0.9190 - val_loss: 0.2663 - learning_rate: 5.0000e-06\n",
            "Epoch 230/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9832 - loss: 0.1621 - val_accuracy: 0.9190 - val_loss: 0.2650 - learning_rate: 5.0000e-06\n",
            "Epoch 231/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9791 - loss: 0.1612 - val_accuracy: 0.9202 - val_loss: 0.2638 - learning_rate: 5.0000e-06\n",
            "Epoch 232/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9806 - loss: 0.1594 - val_accuracy: 0.9190 - val_loss: 0.2626 - learning_rate: 5.0000e-06\n",
            "Epoch 233/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9811 - loss: 0.1611 - val_accuracy: 0.9190 - val_loss: 0.2614 - learning_rate: 5.0000e-06\n",
            "Epoch 234/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9776 - loss: 0.1626 - val_accuracy: 0.9190 - val_loss: 0.2602 - learning_rate: 5.0000e-06\n",
            "Epoch 235/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9816 - loss: 0.1565 - val_accuracy: 0.9190 - val_loss: 0.2591 - learning_rate: 5.0000e-06\n",
            "Epoch 236/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9872 - loss: 0.1442 - val_accuracy: 0.9214 - val_loss: 0.2580 - learning_rate: 5.0000e-06\n",
            "Epoch 237/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9740 - loss: 0.1728 - val_accuracy: 0.9214 - val_loss: 0.2570 - learning_rate: 5.0000e-06\n",
            "Epoch 238/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9760 - loss: 0.1728 - val_accuracy: 0.9226 - val_loss: 0.2559 - learning_rate: 5.0000e-06\n",
            "Epoch 239/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9821 - loss: 0.1581 - val_accuracy: 0.9226 - val_loss: 0.2548 - learning_rate: 5.0000e-06\n",
            "Epoch 240/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9791 - loss: 0.1603 - val_accuracy: 0.9226 - val_loss: 0.2538 - learning_rate: 5.0000e-06\n",
            "Epoch 241/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9730 - loss: 0.1756 - val_accuracy: 0.9226 - val_loss: 0.2527 - learning_rate: 5.0000e-06\n",
            "Epoch 242/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9765 - loss: 0.1662 - val_accuracy: 0.9226 - val_loss: 0.2516 - learning_rate: 5.0000e-06\n",
            "Epoch 243/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9750 - loss: 0.1810 - val_accuracy: 0.9226 - val_loss: 0.2506 - learning_rate: 5.0000e-06\n",
            "Epoch 244/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9837 - loss: 0.1544 - val_accuracy: 0.9226 - val_loss: 0.2496 - learning_rate: 5.0000e-06\n",
            "Epoch 245/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9796 - loss: 0.1677 - val_accuracy: 0.9226 - val_loss: 0.2486 - learning_rate: 5.0000e-06\n",
            "Epoch 246/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1639 - val_accuracy: 0.9238 - val_loss: 0.2477 - learning_rate: 5.0000e-06\n",
            "Epoch 247/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9760 - loss: 0.1712 - val_accuracy: 0.9250 - val_loss: 0.2467 - learning_rate: 5.0000e-06\n",
            "Epoch 248/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9827 - loss: 0.1518 - val_accuracy: 0.9250 - val_loss: 0.2457 - learning_rate: 5.0000e-06\n",
            "Epoch 249/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9770 - loss: 0.1647 - val_accuracy: 0.9250 - val_loss: 0.2447 - learning_rate: 5.0000e-06\n",
            "Epoch 250/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9781 - loss: 0.1642 - val_accuracy: 0.9250 - val_loss: 0.2438 - learning_rate: 5.0000e-06\n",
            "Epoch 251/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.9852 - loss: 0.1582 - val_accuracy: 0.9250 - val_loss: 0.2428 - learning_rate: 5.0000e-06\n",
            "Epoch 252/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9755 - loss: 0.1624 - val_accuracy: 0.9262 - val_loss: 0.2419 - learning_rate: 5.0000e-06\n",
            "Epoch 253/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9821 - loss: 0.1646 - val_accuracy: 0.9274 - val_loss: 0.2409 - learning_rate: 5.0000e-06\n",
            "Epoch 254/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9770 - loss: 0.1649 - val_accuracy: 0.9274 - val_loss: 0.2400 - learning_rate: 5.0000e-06\n",
            "Epoch 255/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9786 - loss: 0.1637 - val_accuracy: 0.9274 - val_loss: 0.2391 - learning_rate: 5.0000e-06\n",
            "Epoch 256/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9801 - loss: 0.1590 - val_accuracy: 0.9274 - val_loss: 0.2382 - learning_rate: 5.0000e-06\n",
            "Epoch 257/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9796 - loss: 0.1541 - val_accuracy: 0.9286 - val_loss: 0.2373 - learning_rate: 5.0000e-06\n",
            "Epoch 258/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1677 - val_accuracy: 0.9286 - val_loss: 0.2364 - learning_rate: 5.0000e-06\n",
            "Epoch 259/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9770 - loss: 0.1592 - val_accuracy: 0.9286 - val_loss: 0.2355 - learning_rate: 5.0000e-06\n",
            "Epoch 260/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9801 - loss: 0.1599 - val_accuracy: 0.9298 - val_loss: 0.2346 - learning_rate: 5.0000e-06\n",
            "Epoch 261/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9816 - loss: 0.1574 - val_accuracy: 0.9298 - val_loss: 0.2338 - learning_rate: 5.0000e-06\n",
            "Epoch 262/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9801 - loss: 0.1545 - val_accuracy: 0.9298 - val_loss: 0.2329 - learning_rate: 5.0000e-06\n",
            "Epoch 263/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9842 - loss: 0.1526 - val_accuracy: 0.9298 - val_loss: 0.2321 - learning_rate: 5.0000e-06\n",
            "Epoch 264/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9791 - loss: 0.1592 - val_accuracy: 0.9298 - val_loss: 0.2313 - learning_rate: 5.0000e-06\n",
            "Epoch 265/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9776 - loss: 0.1652 - val_accuracy: 0.9310 - val_loss: 0.2304 - learning_rate: 5.0000e-06\n",
            "Epoch 266/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9786 - loss: 0.1736 - val_accuracy: 0.9321 - val_loss: 0.2295 - learning_rate: 5.0000e-06\n",
            "Epoch 267/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9806 - loss: 0.1602 - val_accuracy: 0.9321 - val_loss: 0.2287 - learning_rate: 5.0000e-06\n",
            "Epoch 268/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9791 - loss: 0.1621 - val_accuracy: 0.9321 - val_loss: 0.2279 - learning_rate: 5.0000e-06\n",
            "Epoch 269/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9827 - loss: 0.1494 - val_accuracy: 0.9321 - val_loss: 0.2272 - learning_rate: 5.0000e-06\n",
            "Epoch 270/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9740 - loss: 0.1667 - val_accuracy: 0.9333 - val_loss: 0.2264 - learning_rate: 5.0000e-06\n",
            "Epoch 271/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9750 - loss: 0.1759 - val_accuracy: 0.9333 - val_loss: 0.2257 - learning_rate: 5.0000e-06\n",
            "Epoch 272/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9791 - loss: 0.1572 - val_accuracy: 0.9333 - val_loss: 0.2249 - learning_rate: 5.0000e-06\n",
            "Epoch 273/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9786 - loss: 0.1651 - val_accuracy: 0.9345 - val_loss: 0.2243 - learning_rate: 5.0000e-06\n",
            "Epoch 274/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1632 - val_accuracy: 0.9345 - val_loss: 0.2236 - learning_rate: 5.0000e-06\n",
            "Epoch 275/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9821 - loss: 0.1584 - val_accuracy: 0.9357 - val_loss: 0.2229 - learning_rate: 5.0000e-06\n",
            "Epoch 276/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9776 - loss: 0.1635 - val_accuracy: 0.9369 - val_loss: 0.2222 - learning_rate: 5.0000e-06\n",
            "Epoch 277/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9796 - loss: 0.1590 - val_accuracy: 0.9369 - val_loss: 0.2216 - learning_rate: 5.0000e-06\n",
            "Epoch 278/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9740 - loss: 0.1634 - val_accuracy: 0.9381 - val_loss: 0.2209 - learning_rate: 5.0000e-06\n",
            "Epoch 279/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9796 - loss: 0.1614 - val_accuracy: 0.9381 - val_loss: 0.2203 - learning_rate: 5.0000e-06\n",
            "Epoch 280/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9776 - loss: 0.1641 - val_accuracy: 0.9381 - val_loss: 0.2197 - learning_rate: 5.0000e-06\n",
            "Epoch 281/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9765 - loss: 0.1628 - val_accuracy: 0.9381 - val_loss: 0.2191 - learning_rate: 5.0000e-06\n",
            "Epoch 282/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9832 - loss: 0.1565 - val_accuracy: 0.9381 - val_loss: 0.2185 - learning_rate: 5.0000e-06\n",
            "Epoch 283/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9770 - loss: 0.1702 - val_accuracy: 0.9393 - val_loss: 0.2179 - learning_rate: 5.0000e-06\n",
            "Epoch 284/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9776 - loss: 0.1653 - val_accuracy: 0.9405 - val_loss: 0.2172 - learning_rate: 5.0000e-06\n",
            "Epoch 285/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9770 - loss: 0.1643 - val_accuracy: 0.9405 - val_loss: 0.2167 - learning_rate: 5.0000e-06\n",
            "Epoch 286/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9781 - loss: 0.1621 - val_accuracy: 0.9405 - val_loss: 0.2161 - learning_rate: 5.0000e-06\n",
            "Epoch 287/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9781 - loss: 0.1652 - val_accuracy: 0.9405 - val_loss: 0.2155 - learning_rate: 5.0000e-06\n",
            "Epoch 288/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.9801 - loss: 0.1605 - val_accuracy: 0.9405 - val_loss: 0.2150 - learning_rate: 5.0000e-06\n",
            "Epoch 289/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9776 - loss: 0.1665 - val_accuracy: 0.9405 - val_loss: 0.2145 - learning_rate: 5.0000e-06\n",
            "Epoch 290/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9776 - loss: 0.1612 - val_accuracy: 0.9405 - val_loss: 0.2139 - learning_rate: 5.0000e-06\n",
            "Epoch 291/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9842 - loss: 0.1481 - val_accuracy: 0.9405 - val_loss: 0.2134 - learning_rate: 5.0000e-06\n",
            "Epoch 292/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9821 - loss: 0.1617 - val_accuracy: 0.9393 - val_loss: 0.2128 - learning_rate: 5.0000e-06\n",
            "Epoch 293/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9770 - loss: 0.1630 - val_accuracy: 0.9393 - val_loss: 0.2122 - learning_rate: 5.0000e-06\n",
            "Epoch 294/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9760 - loss: 0.1549 - val_accuracy: 0.9393 - val_loss: 0.2117 - learning_rate: 5.0000e-06\n",
            "Epoch 295/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9770 - loss: 0.1645 - val_accuracy: 0.9393 - val_loss: 0.2112 - learning_rate: 5.0000e-06\n",
            "Epoch 296/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9791 - loss: 0.1562 - val_accuracy: 0.9393 - val_loss: 0.2107 - learning_rate: 5.0000e-06\n",
            "Epoch 297/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9796 - loss: 0.1606 - val_accuracy: 0.9393 - val_loss: 0.2101 - learning_rate: 5.0000e-06\n",
            "Epoch 298/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.9781 - loss: 0.1597 - val_accuracy: 0.9393 - val_loss: 0.2097 - learning_rate: 5.0000e-06\n",
            "Epoch 299/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9827 - loss: 0.1567 - val_accuracy: 0.9393 - val_loss: 0.2092 - learning_rate: 5.0000e-06\n",
            "Epoch 300/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9811 - loss: 0.1542 - val_accuracy: 0.9393 - val_loss: 0.2087 - learning_rate: 5.0000e-06\n",
            "Epoch 301/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9801 - loss: 0.1665 - val_accuracy: 0.9393 - val_loss: 0.2082 - learning_rate: 5.0000e-06\n",
            "Epoch 302/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9801 - loss: 0.1622 - val_accuracy: 0.9393 - val_loss: 0.2077 - learning_rate: 5.0000e-06\n",
            "Epoch 303/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9811 - loss: 0.1553 - val_accuracy: 0.9393 - val_loss: 0.2072 - learning_rate: 5.0000e-06\n",
            "Epoch 304/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9821 - loss: 0.1505 - val_accuracy: 0.9393 - val_loss: 0.2068 - learning_rate: 5.0000e-06\n",
            "Epoch 305/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9842 - loss: 0.1574 - val_accuracy: 0.9405 - val_loss: 0.2063 - learning_rate: 5.0000e-06\n",
            "Epoch 306/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9806 - loss: 0.1579 - val_accuracy: 0.9405 - val_loss: 0.2058 - learning_rate: 5.0000e-06\n",
            "Epoch 307/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9821 - loss: 0.1529 - val_accuracy: 0.9405 - val_loss: 0.2054 - learning_rate: 5.0000e-06\n",
            "Epoch 308/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9791 - loss: 0.1554 - val_accuracy: 0.9405 - val_loss: 0.2050 - learning_rate: 5.0000e-06\n",
            "Epoch 309/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9801 - loss: 0.1537 - val_accuracy: 0.9405 - val_loss: 0.2045 - learning_rate: 5.0000e-06\n",
            "Epoch 310/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9776 - loss: 0.1572 - val_accuracy: 0.9405 - val_loss: 0.2040 - learning_rate: 5.0000e-06\n",
            "Epoch 311/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9765 - loss: 0.1596 - val_accuracy: 0.9405 - val_loss: 0.2035 - learning_rate: 5.0000e-06\n",
            "Epoch 312/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9776 - loss: 0.1598 - val_accuracy: 0.9417 - val_loss: 0.2030 - learning_rate: 5.0000e-06\n",
            "Epoch 313/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9796 - loss: 0.1570 - val_accuracy: 0.9417 - val_loss: 0.2025 - learning_rate: 5.0000e-06\n",
            "Epoch 314/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - accuracy: 0.9832 - loss: 0.1487 - val_accuracy: 0.9417 - val_loss: 0.2021 - learning_rate: 5.0000e-06\n",
            "Epoch 315/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step - accuracy: 0.9816 - loss: 0.1537 - val_accuracy: 0.9417 - val_loss: 0.2017 - learning_rate: 5.0000e-06\n",
            "Epoch 316/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9816 - loss: 0.1503 - val_accuracy: 0.9417 - val_loss: 0.2012 - learning_rate: 5.0000e-06\n",
            "Epoch 317/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9806 - loss: 0.1610 - val_accuracy: 0.9440 - val_loss: 0.2008 - learning_rate: 5.0000e-06\n",
            "Epoch 318/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9786 - loss: 0.1606 - val_accuracy: 0.9440 - val_loss: 0.2004 - learning_rate: 5.0000e-06\n",
            "Epoch 319/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9765 - loss: 0.1585 - val_accuracy: 0.9440 - val_loss: 0.2001 - learning_rate: 5.0000e-06\n",
            "Epoch 320/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9735 - loss: 0.1621 - val_accuracy: 0.9429 - val_loss: 0.1997 - learning_rate: 5.0000e-06\n",
            "Epoch 321/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9740 - loss: 0.1609 - val_accuracy: 0.9429 - val_loss: 0.1994 - learning_rate: 5.0000e-06\n",
            "Epoch 322/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9827 - loss: 0.1554 - val_accuracy: 0.9429 - val_loss: 0.1990 - learning_rate: 5.0000e-06\n",
            "Epoch 323/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9806 - loss: 0.1525 - val_accuracy: 0.9429 - val_loss: 0.1987 - learning_rate: 5.0000e-06\n",
            "Epoch 324/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1590 - val_accuracy: 0.9429 - val_loss: 0.1983 - learning_rate: 5.0000e-06\n",
            "Epoch 325/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9796 - loss: 0.1589 - val_accuracy: 0.9429 - val_loss: 0.1979 - learning_rate: 5.0000e-06\n",
            "Epoch 326/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9801 - loss: 0.1669 - val_accuracy: 0.9429 - val_loss: 0.1976 - learning_rate: 5.0000e-06\n",
            "Epoch 327/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9796 - loss: 0.1611 - val_accuracy: 0.9417 - val_loss: 0.1973 - learning_rate: 5.0000e-06\n",
            "Epoch 328/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9796 - loss: 0.1592 - val_accuracy: 0.9417 - val_loss: 0.1969 - learning_rate: 5.0000e-06\n",
            "Epoch 329/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9806 - loss: 0.1516 - val_accuracy: 0.9417 - val_loss: 0.1966 - learning_rate: 5.0000e-06\n",
            "Epoch 330/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9781 - loss: 0.1688 - val_accuracy: 0.9417 - val_loss: 0.1963 - learning_rate: 5.0000e-06\n",
            "Epoch 331/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9781 - loss: 0.1603 - val_accuracy: 0.9429 - val_loss: 0.1960 - learning_rate: 5.0000e-06\n",
            "Epoch 332/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9786 - loss: 0.1563 - val_accuracy: 0.9429 - val_loss: 0.1956 - learning_rate: 5.0000e-06\n",
            "Epoch 333/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9786 - loss: 0.1610 - val_accuracy: 0.9429 - val_loss: 0.1953 - learning_rate: 5.0000e-06\n",
            "Epoch 334/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9704 - loss: 0.1727 - val_accuracy: 0.9429 - val_loss: 0.1950 - learning_rate: 5.0000e-06\n",
            "Epoch 335/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9796 - loss: 0.1592 - val_accuracy: 0.9429 - val_loss: 0.1948 - learning_rate: 5.0000e-06\n",
            "Epoch 336/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9837 - loss: 0.1520 - val_accuracy: 0.9440 - val_loss: 0.1945 - learning_rate: 5.0000e-06\n",
            "Epoch 337/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9811 - loss: 0.1542 - val_accuracy: 0.9440 - val_loss: 0.1942 - learning_rate: 5.0000e-06\n",
            "Epoch 338/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9821 - loss: 0.1556 - val_accuracy: 0.9440 - val_loss: 0.1940 - learning_rate: 5.0000e-06\n",
            "Epoch 339/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9786 - loss: 0.1642 - val_accuracy: 0.9440 - val_loss: 0.1937 - learning_rate: 5.0000e-06\n",
            "Epoch 340/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9852 - loss: 0.1482 - val_accuracy: 0.9440 - val_loss: 0.1935 - learning_rate: 5.0000e-06\n",
            "Epoch 341/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9786 - loss: 0.1634 - val_accuracy: 0.9452 - val_loss: 0.1933 - learning_rate: 5.0000e-06\n",
            "Epoch 342/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9801 - loss: 0.1592 - val_accuracy: 0.9440 - val_loss: 0.1930 - learning_rate: 5.0000e-06\n",
            "Epoch 343/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9801 - loss: 0.1541 - val_accuracy: 0.9440 - val_loss: 0.1928 - learning_rate: 5.0000e-06\n",
            "Epoch 344/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9781 - loss: 0.1666 - val_accuracy: 0.9440 - val_loss: 0.1926 - learning_rate: 5.0000e-06\n",
            "Epoch 345/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9806 - loss: 0.1571 - val_accuracy: 0.9440 - val_loss: 0.1923 - learning_rate: 5.0000e-06\n",
            "Epoch 346/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9796 - loss: 0.1531 - val_accuracy: 0.9440 - val_loss: 0.1921 - learning_rate: 5.0000e-06\n",
            "Epoch 347/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9811 - loss: 0.1548 - val_accuracy: 0.9440 - val_loss: 0.1918 - learning_rate: 5.0000e-06\n",
            "Epoch 348/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9832 - loss: 0.1507 - val_accuracy: 0.9440 - val_loss: 0.1916 - learning_rate: 5.0000e-06\n",
            "Epoch 349/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9811 - loss: 0.1519 - val_accuracy: 0.9440 - val_loss: 0.1914 - learning_rate: 5.0000e-06\n",
            "Epoch 350/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9862 - loss: 0.1404 - val_accuracy: 0.9452 - val_loss: 0.1912 - learning_rate: 5.0000e-06\n",
            "Epoch 351/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9796 - loss: 0.1533 - val_accuracy: 0.9452 - val_loss: 0.1909 - learning_rate: 5.0000e-06\n",
            "Epoch 352/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9796 - loss: 0.1517 - val_accuracy: 0.9452 - val_loss: 0.1907 - learning_rate: 5.0000e-06\n",
            "Epoch 353/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9847 - loss: 0.1528 - val_accuracy: 0.9452 - val_loss: 0.1906 - learning_rate: 5.0000e-06\n",
            "Epoch 354/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9796 - loss: 0.1538 - val_accuracy: 0.9452 - val_loss: 0.1904 - learning_rate: 5.0000e-06\n",
            "Epoch 355/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9827 - loss: 0.1535 - val_accuracy: 0.9452 - val_loss: 0.1903 - learning_rate: 5.0000e-06\n",
            "Epoch 356/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9801 - loss: 0.1605 - val_accuracy: 0.9452 - val_loss: 0.1901 - learning_rate: 5.0000e-06\n",
            "Epoch 357/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9760 - loss: 0.1557 - val_accuracy: 0.9452 - val_loss: 0.1900 - learning_rate: 5.0000e-06\n",
            "Epoch 358/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9816 - loss: 0.1541 - val_accuracy: 0.9452 - val_loss: 0.1898 - learning_rate: 5.0000e-06\n",
            "Epoch 359/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9791 - loss: 0.1538 - val_accuracy: 0.9452 - val_loss: 0.1897 - learning_rate: 5.0000e-06\n",
            "Epoch 360/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9816 - loss: 0.1561 - val_accuracy: 0.9452 - val_loss: 0.1895 - learning_rate: 5.0000e-06\n",
            "Epoch 361/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9791 - loss: 0.1658 - val_accuracy: 0.9452 - val_loss: 0.1893 - learning_rate: 5.0000e-06\n",
            "Epoch 362/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9781 - loss: 0.1532 - val_accuracy: 0.9452 - val_loss: 0.1891 - learning_rate: 5.0000e-06\n",
            "Epoch 363/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9755 - loss: 0.1598 - val_accuracy: 0.9452 - val_loss: 0.1890 - learning_rate: 5.0000e-06\n",
            "Epoch 364/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9755 - loss: 0.1636 - val_accuracy: 0.9452 - val_loss: 0.1888 - learning_rate: 5.0000e-06\n",
            "Epoch 365/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9806 - loss: 0.1573 - val_accuracy: 0.9440 - val_loss: 0.1887 - learning_rate: 5.0000e-06\n",
            "Epoch 366/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9735 - loss: 0.1651 - val_accuracy: 0.9440 - val_loss: 0.1886 - learning_rate: 5.0000e-06\n",
            "Epoch 367/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9760 - loss: 0.1577 - val_accuracy: 0.9440 - val_loss: 0.1884 - learning_rate: 5.0000e-06\n",
            "Epoch 368/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9740 - loss: 0.1725 - val_accuracy: 0.9440 - val_loss: 0.1882 - learning_rate: 5.0000e-06\n",
            "Epoch 369/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9842 - loss: 0.1407 - val_accuracy: 0.9440 - val_loss: 0.1880 - learning_rate: 5.0000e-06\n",
            "Epoch 370/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9796 - loss: 0.1464 - val_accuracy: 0.9440 - val_loss: 0.1878 - learning_rate: 5.0000e-06\n",
            "Epoch 371/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9847 - loss: 0.1555 - val_accuracy: 0.9452 - val_loss: 0.1877 - learning_rate: 5.0000e-06\n",
            "Epoch 372/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9796 - loss: 0.1574 - val_accuracy: 0.9452 - val_loss: 0.1875 - learning_rate: 5.0000e-06\n",
            "Epoch 373/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9816 - loss: 0.1407 - val_accuracy: 0.9452 - val_loss: 0.1873 - learning_rate: 5.0000e-06\n",
            "Epoch 374/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9847 - loss: 0.1494 - val_accuracy: 0.9452 - val_loss: 0.1871 - learning_rate: 5.0000e-06\n",
            "Epoch 375/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9760 - loss: 0.1645 - val_accuracy: 0.9452 - val_loss: 0.1869 - learning_rate: 5.0000e-06\n",
            "Epoch 376/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9811 - loss: 0.1508 - val_accuracy: 0.9452 - val_loss: 0.1867 - learning_rate: 5.0000e-06\n",
            "Epoch 377/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9781 - loss: 0.1665 - val_accuracy: 0.9452 - val_loss: 0.1865 - learning_rate: 5.0000e-06\n",
            "Epoch 378/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9847 - loss: 0.1510 - val_accuracy: 0.9452 - val_loss: 0.1863 - learning_rate: 5.0000e-06\n",
            "Epoch 379/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1559 - val_accuracy: 0.9452 - val_loss: 0.1861 - learning_rate: 5.0000e-06\n",
            "Epoch 380/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9801 - loss: 0.1517 - val_accuracy: 0.9452 - val_loss: 0.1860 - learning_rate: 5.0000e-06\n",
            "Epoch 381/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9816 - loss: 0.1477 - val_accuracy: 0.9452 - val_loss: 0.1858 - learning_rate: 5.0000e-06\n",
            "Epoch 382/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9770 - loss: 0.1579 - val_accuracy: 0.9452 - val_loss: 0.1856 - learning_rate: 5.0000e-06\n",
            "Epoch 383/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9816 - loss: 0.1446 - val_accuracy: 0.9452 - val_loss: 0.1855 - learning_rate: 5.0000e-06\n",
            "Epoch 384/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9776 - loss: 0.1577 - val_accuracy: 0.9464 - val_loss: 0.1853 - learning_rate: 5.0000e-06\n",
            "Epoch 385/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9770 - loss: 0.1597 - val_accuracy: 0.9476 - val_loss: 0.1851 - learning_rate: 5.0000e-06\n",
            "Epoch 386/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9821 - loss: 0.1508 - val_accuracy: 0.9476 - val_loss: 0.1849 - learning_rate: 5.0000e-06\n",
            "Epoch 387/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9847 - loss: 0.1494 - val_accuracy: 0.9488 - val_loss: 0.1848 - learning_rate: 5.0000e-06\n",
            "Epoch 388/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9791 - loss: 0.1553 - val_accuracy: 0.9488 - val_loss: 0.1847 - learning_rate: 5.0000e-06\n",
            "Epoch 389/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9827 - loss: 0.1493 - val_accuracy: 0.9488 - val_loss: 0.1845 - learning_rate: 5.0000e-06\n",
            "Epoch 390/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9816 - loss: 0.1516 - val_accuracy: 0.9488 - val_loss: 0.1844 - learning_rate: 5.0000e-06\n",
            "Epoch 391/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9811 - loss: 0.1552 - val_accuracy: 0.9488 - val_loss: 0.1842 - learning_rate: 5.0000e-06\n",
            "Epoch 392/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9760 - loss: 0.1667 - val_accuracy: 0.9500 - val_loss: 0.1841 - learning_rate: 5.0000e-06\n",
            "Epoch 393/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9806 - loss: 0.1548 - val_accuracy: 0.9500 - val_loss: 0.1840 - learning_rate: 5.0000e-06\n",
            "Epoch 394/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9816 - loss: 0.1581 - val_accuracy: 0.9500 - val_loss: 0.1839 - learning_rate: 5.0000e-06\n",
            "Epoch 395/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9821 - loss: 0.1502 - val_accuracy: 0.9512 - val_loss: 0.1838 - learning_rate: 5.0000e-06\n",
            "Epoch 396/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9811 - loss: 0.1499 - val_accuracy: 0.9512 - val_loss: 0.1838 - learning_rate: 5.0000e-06\n",
            "Epoch 397/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9786 - loss: 0.1527 - val_accuracy: 0.9512 - val_loss: 0.1837 - learning_rate: 5.0000e-06\n",
            "Epoch 398/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9811 - loss: 0.1598 - val_accuracy: 0.9512 - val_loss: 0.1836 - learning_rate: 5.0000e-06\n",
            "Epoch 399/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1539 - val_accuracy: 0.9512 - val_loss: 0.1836 - learning_rate: 5.0000e-06\n",
            "Epoch 400/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1557 - val_accuracy: 0.9512 - val_loss: 0.1835 - learning_rate: 5.0000e-06\n",
            "Epoch 401/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9760 - loss: 0.1538 - val_accuracy: 0.9512 - val_loss: 0.1835 - learning_rate: 5.0000e-06\n",
            "Epoch 402/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9811 - loss: 0.1563 - val_accuracy: 0.9512 - val_loss: 0.1834 - learning_rate: 5.0000e-06\n",
            "Epoch 403/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9786 - loss: 0.1602 - val_accuracy: 0.9512 - val_loss: 0.1833 - learning_rate: 5.0000e-06\n",
            "Epoch 404/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9842 - loss: 0.1511 - val_accuracy: 0.9512 - val_loss: 0.1833 - learning_rate: 5.0000e-06\n",
            "Epoch 405/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9847 - loss: 0.1484 - val_accuracy: 0.9512 - val_loss: 0.1832 - learning_rate: 5.0000e-06\n",
            "Epoch 406/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9842 - loss: 0.1392 - val_accuracy: 0.9512 - val_loss: 0.1831 - learning_rate: 5.0000e-06\n",
            "Epoch 407/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9852 - loss: 0.1491 - val_accuracy: 0.9512 - val_loss: 0.1831 - learning_rate: 5.0000e-06\n",
            "Epoch 408/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9745 - loss: 0.1622 - val_accuracy: 0.9512 - val_loss: 0.1830 - learning_rate: 5.0000e-06\n",
            "Epoch 409/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9796 - loss: 0.1555 - val_accuracy: 0.9512 - val_loss: 0.1829 - learning_rate: 5.0000e-06\n",
            "Epoch 410/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9776 - loss: 0.1569 - val_accuracy: 0.9512 - val_loss: 0.1828 - learning_rate: 5.0000e-06\n",
            "Epoch 411/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9827 - loss: 0.1496 - val_accuracy: 0.9512 - val_loss: 0.1827 - learning_rate: 5.0000e-06\n",
            "Epoch 412/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9872 - loss: 0.1425 - val_accuracy: 0.9512 - val_loss: 0.1826 - learning_rate: 5.0000e-06\n",
            "Epoch 413/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9832 - loss: 0.1508 - val_accuracy: 0.9512 - val_loss: 0.1825 - learning_rate: 5.0000e-06\n",
            "Epoch 414/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9816 - loss: 0.1447 - val_accuracy: 0.9512 - val_loss: 0.1824 - learning_rate: 5.0000e-06\n",
            "Epoch 415/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9821 - loss: 0.1529 - val_accuracy: 0.9512 - val_loss: 0.1823 - learning_rate: 5.0000e-06\n",
            "Epoch 416/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - accuracy: 0.9776 - loss: 0.1556 - val_accuracy: 0.9512 - val_loss: 0.1821 - learning_rate: 5.0000e-06\n",
            "Epoch 417/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.9811 - loss: 0.1476 - val_accuracy: 0.9512 - val_loss: 0.1821 - learning_rate: 5.0000e-06\n",
            "Epoch 418/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9832 - loss: 0.1401 - val_accuracy: 0.9512 - val_loss: 0.1820 - learning_rate: 5.0000e-06\n",
            "Epoch 419/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9821 - loss: 0.1471 - val_accuracy: 0.9512 - val_loss: 0.1819 - learning_rate: 5.0000e-06\n",
            "Epoch 420/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9816 - loss: 0.1499 - val_accuracy: 0.9512 - val_loss: 0.1818 - learning_rate: 5.0000e-06\n",
            "Epoch 421/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9837 - loss: 0.1426 - val_accuracy: 0.9512 - val_loss: 0.1817 - learning_rate: 5.0000e-06\n",
            "Epoch 422/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9750 - loss: 0.1526 - val_accuracy: 0.9512 - val_loss: 0.1816 - learning_rate: 5.0000e-06\n",
            "Epoch 423/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9837 - loss: 0.1481 - val_accuracy: 0.9500 - val_loss: 0.1816 - learning_rate: 5.0000e-06\n",
            "Epoch 424/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9770 - loss: 0.1540 - val_accuracy: 0.9500 - val_loss: 0.1815 - learning_rate: 5.0000e-06\n",
            "Epoch 425/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9791 - loss: 0.1513 - val_accuracy: 0.9500 - val_loss: 0.1814 - learning_rate: 5.0000e-06\n",
            "Epoch 426/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9847 - loss: 0.1459 - val_accuracy: 0.9500 - val_loss: 0.1813 - learning_rate: 5.0000e-06\n",
            "Epoch 427/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9806 - loss: 0.1520 - val_accuracy: 0.9500 - val_loss: 0.1812 - learning_rate: 5.0000e-06\n",
            "Epoch 428/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9847 - loss: 0.1484 - val_accuracy: 0.9500 - val_loss: 0.1811 - learning_rate: 5.0000e-06\n",
            "Epoch 429/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9811 - loss: 0.1516 - val_accuracy: 0.9500 - val_loss: 0.1810 - learning_rate: 5.0000e-06\n",
            "Epoch 430/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9816 - loss: 0.1427 - val_accuracy: 0.9500 - val_loss: 0.1810 - learning_rate: 5.0000e-06\n",
            "Epoch 431/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9796 - loss: 0.1492 - val_accuracy: 0.9500 - val_loss: 0.1809 - learning_rate: 5.0000e-06\n",
            "Epoch 432/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9776 - loss: 0.1497 - val_accuracy: 0.9500 - val_loss: 0.1809 - learning_rate: 5.0000e-06\n",
            "Epoch 433/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9786 - loss: 0.1541 - val_accuracy: 0.9500 - val_loss: 0.1808 - learning_rate: 5.0000e-06\n",
            "Epoch 434/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9811 - loss: 0.1481 - val_accuracy: 0.9500 - val_loss: 0.1808 - learning_rate: 5.0000e-06\n",
            "Epoch 435/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9776 - loss: 0.1539 - val_accuracy: 0.9500 - val_loss: 0.1808 - learning_rate: 5.0000e-06\n",
            "Epoch 436/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9806 - loss: 0.1577 - val_accuracy: 0.9512 - val_loss: 0.1808 - learning_rate: 5.0000e-06\n",
            "Epoch 437/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9811 - loss: 0.1460 - val_accuracy: 0.9512 - val_loss: 0.1808 - learning_rate: 5.0000e-06\n",
            "Epoch 438/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9806 - loss: 0.1457 - val_accuracy: 0.9500 - val_loss: 0.1807 - learning_rate: 5.0000e-06\n",
            "Epoch 439/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.9806 - loss: 0.1522 - val_accuracy: 0.9500 - val_loss: 0.1807 - learning_rate: 5.0000e-06\n",
            "Epoch 440/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9816 - loss: 0.1505 - val_accuracy: 0.9500 - val_loss: 0.1807 - learning_rate: 5.0000e-06\n",
            "Epoch 441/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9811 - loss: 0.1504 - val_accuracy: 0.9500 - val_loss: 0.1807 - learning_rate: 5.0000e-06\n",
            "Epoch 442/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9857 - loss: 0.1448 - val_accuracy: 0.9500 - val_loss: 0.1808 - learning_rate: 5.0000e-06\n",
            "Epoch 443/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9801 - loss: 0.1511 - val_accuracy: 0.9500 - val_loss: 0.1808 - learning_rate: 5.0000e-06\n",
            "Epoch 444/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9791 - loss: 0.1516 - val_accuracy: 0.9500 - val_loss: 0.1808 - learning_rate: 5.0000e-06\n",
            "Epoch 445/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9857 - loss: 0.1400 - val_accuracy: 0.9500 - val_loss: 0.1809 - learning_rate: 5.0000e-06\n",
            "Epoch 446/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9816 - loss: 0.1396 - val_accuracy: 0.9500 - val_loss: 0.1809 - learning_rate: 5.0000e-06\n",
            "Epoch 447/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9765 - loss: 0.1523 - val_accuracy: 0.9500 - val_loss: 0.1809 - learning_rate: 5.0000e-06\n",
            "Epoch 448/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9852 - loss: 0.1421 - val_accuracy: 0.9500 - val_loss: 0.1809 - learning_rate: 5.0000e-06\n",
            "Epoch 449/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9821 - loss: 0.1499 - val_accuracy: 0.9500 - val_loss: 0.1809 - learning_rate: 5.0000e-06\n",
            "Epoch 450/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9811 - loss: 0.1496 - val_accuracy: 0.9500 - val_loss: 0.1810 - learning_rate: 5.0000e-06\n",
            "Epoch 451/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9811 - loss: 0.1496 - val_accuracy: 0.9500 - val_loss: 0.1810 - learning_rate: 5.0000e-06\n",
            "Epoch 452/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9832 - loss: 0.1378 - val_accuracy: 0.9500 - val_loss: 0.1810 - learning_rate: 5.0000e-06\n",
            "Epoch 453/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9852 - loss: 0.1424 - val_accuracy: 0.9500 - val_loss: 0.1810 - learning_rate: 5.0000e-06\n",
            "Epoch 454/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9796 - loss: 0.1543 - val_accuracy: 0.9500 - val_loss: 0.1809 - learning_rate: 5.0000e-06\n",
            "Epoch 455/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9837 - loss: 0.1549 - val_accuracy: 0.9500 - val_loss: 0.1809 - learning_rate: 5.0000e-06\n",
            "Epoch 456/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9786 - loss: 0.1575 - val_accuracy: 0.9500 - val_loss: 0.1809 - learning_rate: 5.0000e-06\n",
            "Epoch 457/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9852 - loss: 0.1373 - val_accuracy: 0.9500 - val_loss: 0.1808 - learning_rate: 5.0000e-06\n",
            "Epoch 458/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9827 - loss: 0.1416 - val_accuracy: 0.9500 - val_loss: 0.1808 - learning_rate: 5.0000e-06\n",
            "Epoch 459/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9837 - loss: 0.1405 - val_accuracy: 0.9500 - val_loss: 0.1807 - learning_rate: 5.0000e-06\n",
            "Epoch 460/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.9806 - loss: 0.1517 - val_accuracy: 0.9500 - val_loss: 0.1807 - learning_rate: 5.0000e-06\n",
            "Epoch 461/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9852 - loss: 0.1448 - val_accuracy: 0.9500 - val_loss: 0.1806 - learning_rate: 5.0000e-06\n",
            "Epoch 462/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9837 - loss: 0.1564 - val_accuracy: 0.9500 - val_loss: 0.1806 - learning_rate: 5.0000e-06\n",
            "Epoch 463/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.9872 - loss: 0.1343 - val_accuracy: 0.9500 - val_loss: 0.1806 - learning_rate: 5.0000e-06\n",
            "Epoch 464/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9806 - loss: 0.1479 - val_accuracy: 0.9512 - val_loss: 0.1806 - learning_rate: 5.0000e-06\n",
            "Epoch 465/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9821 - loss: 0.1432 - val_accuracy: 0.9512 - val_loss: 0.1806 - learning_rate: 5.0000e-06\n",
            "Epoch 466/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9801 - loss: 0.1493 - val_accuracy: 0.9512 - val_loss: 0.1805 - learning_rate: 5.0000e-06\n",
            "Epoch 467/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.9801 - loss: 0.1492 - val_accuracy: 0.9512 - val_loss: 0.1805 - learning_rate: 5.0000e-06\n",
            "Epoch 468/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9816 - loss: 0.1500 - val_accuracy: 0.9512 - val_loss: 0.1804 - learning_rate: 5.0000e-06\n",
            "Epoch 469/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9816 - loss: 0.1495 - val_accuracy: 0.9512 - val_loss: 0.1803 - learning_rate: 5.0000e-06\n",
            "Epoch 470/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9760 - loss: 0.1513 - val_accuracy: 0.9512 - val_loss: 0.1803 - learning_rate: 5.0000e-06\n",
            "Epoch 471/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9791 - loss: 0.1450 - val_accuracy: 0.9512 - val_loss: 0.1802 - learning_rate: 5.0000e-06\n",
            "Epoch 472/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9811 - loss: 0.1536 - val_accuracy: 0.9500 - val_loss: 0.1801 - learning_rate: 5.0000e-06\n",
            "Epoch 473/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9821 - loss: 0.1486 - val_accuracy: 0.9512 - val_loss: 0.1800 - learning_rate: 5.0000e-06\n",
            "Epoch 474/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9827 - loss: 0.1373 - val_accuracy: 0.9512 - val_loss: 0.1800 - learning_rate: 5.0000e-06\n",
            "Epoch 475/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9847 - loss: 0.1416 - val_accuracy: 0.9512 - val_loss: 0.1800 - learning_rate: 5.0000e-06\n",
            "Epoch 476/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9755 - loss: 0.1521 - val_accuracy: 0.9512 - val_loss: 0.1799 - learning_rate: 5.0000e-06\n",
            "Epoch 477/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9827 - loss: 0.1499 - val_accuracy: 0.9512 - val_loss: 0.1798 - learning_rate: 5.0000e-06\n",
            "Epoch 478/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9883 - loss: 0.1410 - val_accuracy: 0.9512 - val_loss: 0.1798 - learning_rate: 5.0000e-06\n",
            "Epoch 479/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9801 - loss: 0.1416 - val_accuracy: 0.9512 - val_loss: 0.1797 - learning_rate: 5.0000e-06\n",
            "Epoch 480/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9832 - loss: 0.1458 - val_accuracy: 0.9512 - val_loss: 0.1795 - learning_rate: 5.0000e-06\n",
            "Epoch 481/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9847 - loss: 0.1353 - val_accuracy: 0.9512 - val_loss: 0.1795 - learning_rate: 5.0000e-06\n",
            "Epoch 482/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.9847 - loss: 0.1445 - val_accuracy: 0.9512 - val_loss: 0.1794 - learning_rate: 5.0000e-06\n",
            "Epoch 483/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9832 - loss: 0.1474 - val_accuracy: 0.9512 - val_loss: 0.1793 - learning_rate: 5.0000e-06\n",
            "Epoch 484/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9821 - loss: 0.1434 - val_accuracy: 0.9524 - val_loss: 0.1793 - learning_rate: 5.0000e-06\n",
            "Epoch 485/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9801 - loss: 0.1472 - val_accuracy: 0.9524 - val_loss: 0.1792 - learning_rate: 5.0000e-06\n",
            "Epoch 486/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9796 - loss: 0.1425 - val_accuracy: 0.9524 - val_loss: 0.1792 - learning_rate: 5.0000e-06\n",
            "Epoch 487/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9847 - loss: 0.1415 - val_accuracy: 0.9524 - val_loss: 0.1791 - learning_rate: 5.0000e-06\n",
            "Epoch 488/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9821 - loss: 0.1494 - val_accuracy: 0.9512 - val_loss: 0.1791 - learning_rate: 5.0000e-06\n",
            "Epoch 489/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9816 - loss: 0.1443 - val_accuracy: 0.9512 - val_loss: 0.1791 - learning_rate: 5.0000e-06\n",
            "Epoch 490/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9821 - loss: 0.1428 - val_accuracy: 0.9512 - val_loss: 0.1791 - learning_rate: 5.0000e-06\n",
            "Epoch 491/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.9857 - loss: 0.1451 - val_accuracy: 0.9512 - val_loss: 0.1790 - learning_rate: 5.0000e-06\n",
            "Epoch 492/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9827 - loss: 0.1532 - val_accuracy: 0.9512 - val_loss: 0.1790 - learning_rate: 5.0000e-06\n",
            "Epoch 493/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9862 - loss: 0.1397 - val_accuracy: 0.9512 - val_loss: 0.1790 - learning_rate: 5.0000e-06\n",
            "Epoch 494/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9816 - loss: 0.1394 - val_accuracy: 0.9512 - val_loss: 0.1791 - learning_rate: 5.0000e-06\n",
            "Epoch 495/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9842 - loss: 0.1374 - val_accuracy: 0.9512 - val_loss: 0.1791 - learning_rate: 5.0000e-06\n",
            "Epoch 496/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9837 - loss: 0.1404 - val_accuracy: 0.9512 - val_loss: 0.1791 - learning_rate: 5.0000e-06\n",
            "Epoch 497/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.9816 - loss: 0.1448 - val_accuracy: 0.9512 - val_loss: 0.1791 - learning_rate: 5.0000e-06\n",
            "Epoch 498/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9781 - loss: 0.1469 - val_accuracy: 0.9512 - val_loss: 0.1791 - learning_rate: 5.0000e-06\n",
            "Epoch 499/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.9816 - loss: 0.1443 - val_accuracy: 0.9512 - val_loss: 0.1791 - learning_rate: 5.0000e-06\n",
            "Epoch 500/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.9852 - loss: 0.1504 - val_accuracy: 0.9512 - val_loss: 0.1791 - learning_rate: 5.0000e-06\n"
          ]
        }
      ],
      "source": [
        "# it may takes several times to reach the reported performance\n",
        "lr = 1e-4\n",
        "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=keras.optimizers.Adam(lr),metrics=['accuracy'])\n",
        "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
        "history = DD_Net.fit([X_0,X_1],Y,\n",
        "            batch_size=len(Y),\n",
        "            epochs=400,\n",
        "            verbose=True,\n",
        "            shuffle=True,\n",
        "            callbacks=[lrScheduler],\n",
        "            validation_data=([X_test_0,X_test_1],Y_test)\n",
        "            )\n",
        "\n",
        "lr = 1e-4\n",
        "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=keras.optimizers.Adam(lr),metrics=['accuracy'])\n",
        "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
        "history = DD_Net.fit([X_0,X_1],Y,\n",
        "            batch_size=len(Y),\n",
        "            epochs=500,\n",
        "            verbose=True,\n",
        "            shuffle=True,\n",
        "            callbacks=[lrScheduler],\n",
        "            validation_data=([X_test_0,X_test_1],Y_test)\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqh2oDD4ixIS"
      },
      "source": [
        "6.Plotting results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "_Tx0Txay0v5-",
        "outputId": "8fe329c0-1939-4d2d-ea01-7d33059a6423"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "J_K4G9CuTA4d",
        "outputId": "04e2f6e3-e285-4650-c0b3-04f05def1d6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Y_pred = DD_Net.predict([X_test_0,X_test_1])\n",
        "labels = ['Grab', 'Tap', 'Expand', 'Pinch', 'RC', 'RCC', 'SR', 'SL', 'SU', 'SD', 'SX', 'S+', 'SV', 'Shake']\n",
        "\n",
        "y_true = []\n",
        "for i in np.argmax(Y_test,axis=1):\n",
        "    y_true.append(labels[i])\n",
        "\n",
        "y_pred = []\n",
        "for i in np.argmax(Y_pred,axis=1):\n",
        "    y_pred.append(labels[i])\n",
        "\n",
        "cm_analysis(y_true,y_pred, 'SHREC_14.png', labels, ymap=None, figsize=(8,8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe0Zw66yW47F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
