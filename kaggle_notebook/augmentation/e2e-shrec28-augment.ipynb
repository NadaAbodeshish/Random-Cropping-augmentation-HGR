{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-27T07:35:24.985751Z",
     "iopub.status.busy": "2024-11-27T07:35:24.985466Z",
     "iopub.status.idle": "2024-11-27T07:35:28.857588Z",
     "shell.execute_reply": "2024-11-27T07:35:28.856364Z",
     "shell.execute_reply.started": "2024-11-27T07:35:24.985724Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'augmented-e2eET-Skeleton-Based-HGR-Using-Data-Level-Fusion'...\n",
      "remote: Enumerating objects: 487, done.\u001b[K\n",
      "remote: Counting objects: 100% (185/185), done.\u001b[K\n",
      "remote: Compressing objects: 100% (119/119), done.\u001b[K\n",
      "remote: Total 487 (delta 134), reused 116 (delta 65), pack-reused 302 (from 1)\u001b[K\n",
      "Receiving objects: 100% (487/487), 58.83 MiB | 36.01 MiB/s, done.\n",
      "Resolving deltas: 100% (313/313), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone clone hhttps://github.com/NadaAbodeshish/Random-Cropping-augmentation-HGR.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T07:35:28.860417Z",
     "iopub.status.busy": "2024-11-27T07:35:28.860033Z",
     "iopub.status.idle": "2024-11-27T07:35:28.867913Z",
     "shell.execute_reply": "2024-11-27T07:35:28.866955Z",
     "shell.execute_reply.started": "2024-11-27T07:35:28.860388Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/augmented-e2eET-Skeleton-Based-HGR-Using-Data-Level-Fusion\n"
     ]
    }
   ],
   "source": [
    "%cd Random-Cropping-augmentation-HGR/e2eET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T07:35:28.869197Z",
     "iopub.status.busy": "2024-11-27T07:35:28.868855Z",
     "iopub.status.idle": "2024-11-27T07:35:29.923049Z",
     "shell.execute_reply": "2024-11-27T07:35:29.921877Z",
     "shell.execute_reply.started": "2024-11-27T07:35:28.869158Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'SHREC2017.mVOs-3d.28g-noisy(raw).960px-[allVOs].adaptive-mean'\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/shrec28-aug/augmenttttdrrsds-e2eET-Skeleton-Based-HGR-Using-Data-Level-Fusion/images_d_sh28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T07:35:29.926308Z",
     "iopub.status.busy": "2024-11-27T07:35:29.925834Z",
     "iopub.status.idle": "2024-11-27T07:37:18.992308Z",
     "shell.execute_reply": "2024-11-27T07:37:18.991114Z",
     "shell.execute_reply.started": "2024-11-27T07:35:29.926248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/shrec28-aug/augmenttttdrrsds-e2eET-Skeleton-Based-HGR-Using-Data-Level-Fusion/images_d_sh28/* /kaggle/working/Random-Cropping-augmentation-HGR/e2eET/images_d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T07:37:18.994040Z",
     "iopub.status.busy": "2024-11-27T07:37:18.993757Z",
     "iopub.status.idle": "2024-11-27T07:37:19.001085Z",
     "shell.execute_reply": "2024-11-27T07:37:19.000105Z",
     "shell.execute_reply.started": "2024-11-27T07:37:18.994011Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/augmented-e2eET-Skeleton-Based-HGR-Using-Data-Level-Fusion/experiments.server\n"
     ]
    }
   ],
   "source": [
    "%cd experiments.server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T07:37:19.002569Z",
     "iopub.status.busy": "2024-11-27T07:37:19.002307Z",
     "iopub.status.idle": "2024-11-27T07:37:46.886697Z",
     "shell.execute_reply": "2024-11-27T07:37:46.885562Z",
     "shell.execute_reply.started": "2024-11-27T07:37:19.002544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorchcv\n",
      "  Downloading pytorchcv-0.0.73-py2.py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.2/134.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorchcv) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pytorchcv) (2.32.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from pytorchcv) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from pytorchcv) (0.19.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pytorchcv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pytorchcv) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pytorchcv) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pytorchcv) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->pytorchcv) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->pytorchcv) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->pytorchcv) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->pytorchcv) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->pytorchcv) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->pytorchcv) (2024.6.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->pytorchcv) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->pytorchcv) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->pytorchcv) (1.3.0)\n",
      "Downloading pytorchcv-0.0.73-py2.py3-none-any.whl (585 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.2/585.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytorchcv\n",
      "Successfully installed pytorchcv-0.0.73\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting geffnet\n",
      "  Downloading geffnet-1.0.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.10/site-packages (from geffnet) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from geffnet) (0.19.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->geffnet) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->geffnet) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->geffnet) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->geffnet) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->geffnet) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->geffnet) (2024.6.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->geffnet) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->geffnet) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4->geffnet) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4->geffnet) (1.3.0)\n",
      "Downloading geffnet-1.0.2-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m103.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: geffnet\n",
      "Successfully installed geffnet-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorchcv\n",
    "!pip install matplotlib\n",
    "!pip install geffnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T07:37:46.888691Z",
     "iopub.status.busy": "2024-11-27T07:37:46.888324Z",
     "iopub.status.idle": "2024-11-27T10:47:15.982426Z",
     "shell.execute_reply": "2024-11-27T10:47:15.981486Z",
     "shell.execute_reply.started": "2024-11-27T07:37:46.888654Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Number of items in training split: 1960\n",
      "Debug: Number of items in validation split: 840\n",
      "Debug: Expected classes: 28, Detected classes: 28\n",
      "Debug: Detected class vocab: ['01-Grab', '02-Tap', '03-Expand', '04-Pinch', '05-RotationCW', '06-RotationCCW', '07-SwipeRight', '08-SwipeLeft', '09-SwipeUp', '10-SwipeDown', '11-SwipeX', '12-Swipe+', '13-SwipeV', '14-Shake', '15-Grab', '16-Tap', '17-Expand', '18-Pinch', '19-RotationCW', '20-RotationCCW', '21-SwipeRight', '22-SwipeLeft', '23-SwipeUp', '24-SwipeDown', '25-SwipeX', '26-Swipe+', '27-SwipeV', '28-Shake']\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "100%|███████████████████████████████████████| 83.3M/83.3M [00:00<00:00, 162MB/s]\n",
      "\n",
      "metrics= [<bound method accuracyMultiVOs_0 of e2eTunerLossWrapper()>, <bound method accuracyMultiVOs_1 of e2eTunerLossWrapper()>, <bound method accuracyMultiVOs_2 of e2eTunerLossWrapper()>, <bound method e2eTunerLossWrapper.accuracyTuner of e2eTunerLossWrapper()>]\n",
      "Batch Size: 16, Image Size: 224, Epochs: [20, 20]\n",
      "\n",
      "Model FROZEN [a].\n",
      "/opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      ">> @i224a --- pct_start: 0.55 --- learning_rate: 0.0005754399462603033\n",
      "epoch     train_loss  valid_loss  accuracyTopDown  accuracyCustom  accuracyFrontAway  accuracyTuner  time    \n",
      "0         10.815847   9.025798    0.254762         0.273810        0.366667           0.429762       03:31     \n",
      "1         8.686148    7.298688    0.290476         0.342857        0.464286           0.686905       03:33     \n",
      "2         7.235488    6.757589    0.297619         0.420238        0.482143           0.736905       03:33     \n",
      "3         6.430855    6.113835    0.335714         0.458333        0.551190           0.797619       03:33     \n",
      "4         6.102468    5.758797    0.344048         0.464286        0.575000           0.813095       03:32     \n",
      "5         5.539978    5.722314    0.354762         0.488095        0.554762           0.827381       03:33     \n",
      "6         5.350252    5.362844    0.401190         0.513095        0.566667           0.833333       03:31     \n",
      "7         5.162625    5.137985    0.396429         0.521429        0.604762           0.858333       03:32     \n",
      "8         4.872863    5.122716    0.401190         0.552381        0.579762           0.855952       03:32     \n",
      "9         4.622206    4.764429    0.422619         0.539286        0.641667           0.888095       03:32     \n",
      "10        4.458619    4.765732    0.425000         0.569048        0.620238           0.877381       03:33     \n",
      "11        4.239514    4.529051    0.430952         0.596429        0.640476           0.896429       03:33     \n",
      "12        4.153553    4.358402    0.441667         0.584524        0.669048           0.904762       03:33     \n",
      "13        3.944614    4.388873    0.452381         0.589286        0.667857           0.892857       03:33     \n",
      "14        3.753461    4.343135    0.473810         0.596429        0.666667           0.900000       03:34     \n",
      "15        3.599386    4.376144    0.452381         0.627381        0.660714           0.904762       03:32     \n",
      "16        3.497019    4.169002    0.461905         0.653571        0.664286           0.911905       03:32     \n",
      "17        3.321120    4.149634    0.458333         0.625000        0.691667           0.910714       03:33     \n",
      "18        3.257288    4.014041    0.467857         0.648810        0.680952           0.908333       03:33     \n",
      "19        3.146434    4.054487    0.455952         0.647619        0.682143           0.920238       03:33     \n",
      "@outsidersCustomCallback: Training completed and best i224a model loaded!\n",
      "-- [ i224a] - 0.4560 - 0.6476 - 0.6821 - 0.9202 - 01:13\n",
      "\n",
      "Model UNFROZEN [b].\n",
      ">> @i224b --- pct_start: 0.55 --- learning_rate: 3.981071586167673e-06\n",
      "epoch     train_loss  valid_loss  accuracyTopDown  accuracyCustom  accuracyFrontAway  accuracyTuner  time    \n",
      "0         3.304208    4.005613    0.482143         0.653571        0.680952           0.915476       03:46     \n",
      "1         3.169228    4.049213    0.488095         0.613095        0.696429           0.922619       03:45     \n",
      "2         3.096332    4.173522    0.489286         0.609524        0.677381           0.914286       03:44     \n",
      "3         3.053171    3.977973    0.475000         0.644048        0.685714           0.913095       03:44     \n",
      "4         2.866075    3.818126    0.486905         0.658333        0.715476           0.933333       03:46     \n",
      "5         2.910632    3.848245    0.497619         0.651190        0.705952           0.908333       03:46     \n",
      "6         2.733648    3.698801    0.514286         0.679762        0.704762           0.925000       03:46     \n",
      "7         2.644807    3.730847    0.517857         0.669048        0.703571           0.927381       03:46     \n",
      "8         2.737339    3.719051    0.503571         0.673810        0.708333           0.921429       03:47     \n",
      "9         2.702701    3.873098    0.522619         0.644048        0.680952           0.921429       03:47     \n",
      "10        2.611775    3.630914    0.530952         0.666667        0.715476           0.934524       03:45     \n",
      "11        2.537593    3.581198    0.517857         0.680952        0.720238           0.944048       03:45     \n",
      "12        2.481658    3.552161    0.526190         0.672619        0.745238           0.941667       03:46     \n",
      "13        2.506356    3.468040    0.536905         0.690476        0.738095           0.934524       03:45     \n",
      "14        2.358389    3.488487    0.538095         0.675000        0.723810           0.935714       03:47     \n",
      "15        2.324430    3.585180    0.538095         0.667857        0.710714           0.927381       03:46     \n",
      "16        2.293655    3.624118    0.515476         0.677381        0.726190           0.930952       03:46     \n",
      "17        2.330690    3.686978    0.534524         0.645238        0.719048           0.926190       03:45     \n",
      "18        2.218697    3.474506    0.540476         0.690476        0.725000           0.933333       03:43     \n",
      "19        2.321339    3.674325    0.535714         0.669048        0.697619           0.926190       03:42     \n",
      "@outsidersCustomCallback: Training completed and best i224b model loaded!\n",
      "-- [ i224b] - 0.5179 - 0.6810 - 0.7202 - 0.9440 - 02:30\n",
      ">> @i224bf --- pct_start: 0.55 --- learning_rate: 3.981071586167673e-07\n",
      "epoch     train_loss  valid_loss  accuracyTopDown  accuracyCustom  accuracyFrontAway  accuracyTuner  time    \n",
      "0         2.531376    3.548153    0.520238         0.691667        0.708333           0.939286       03:44     \n",
      "1         2.557925    3.565753    0.525000         0.670238        0.735714           0.935714       03:46     \n",
      "2         2.478153    3.738431    0.516667         0.672619        0.703571           0.940476       03:46     \n",
      "3         2.498265    3.458413    0.535714         0.704762        0.717857           0.945238       03:46     \n",
      "4         2.465227    3.633940    0.516667         0.673810        0.719048           0.939286       03:45     \n",
      "5         2.419861    3.588605    0.527381         0.682143        0.713095           0.944048       03:45     \n",
      "6         2.517255    3.560912    0.522619         0.692857        0.715476           0.941667       03:45     \n",
      "7         2.388534    3.621055    0.523810         0.672619        0.720238           0.938095       03:45     \n",
      "8         2.373010    3.573164    0.538095         0.677381        0.719048           0.936905       03:47     \n",
      "9         2.469645    3.633332    0.520238         0.670238        0.719048           0.939286       03:48     \n",
      "@outsidersCustomCallback: Training completed and best i224bf model loaded!\n",
      "-- [i224bf] - 0.5357 - 0.7048 - 0.7179 - 0.9452 - 03:08\n",
      "Time Elapsed ~ 03h:08m:09s\n",
      "accuracies@e2eT: {'Top-Down': 0.5357, 'Custom': 0.7048, 'Front-Away': 0.7179, 'Tuner': 0.9452}\n",
      "e2eT_MaxA: 0.9452 @03h:09m:07s\n",
      "Training completed @mVO.e2eEnsembleTuning ->> [d0d8]-271124.0738 ->- e2eT-SHREC2017.3d-28G-[td_cm_fa]-i20\n"
     ]
    }
   ],
   "source": [
    "!python mVO.e2eEnsembleTuning.py -IG 0 -nC 28 -mVOs top-down custom front-away -dsN SHREC2017 -IISE 0 -ISIS 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6172537,
     "sourceId": 10023550,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
